{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5nAwpo6Okni",
        "colab_type": "text"
      },
      "source": [
        "#### **IMPORTANT** : **THE** **ORIGINAL** **DATASET** \"**SKIN** **CANCER** **MNIST** : **HAM10000**\" **HAS** **BEEN** **PREPROCESSED** **ALREADY** **IN** **THE** **JUPYTER** **NOTEBOOK** \"**SKIN_CANCER_MNIST_HAM10000_EDA_DATAPREPROCESSING**.**ipynb**\". \n",
        "\n",
        "##### **THE** **CSV** **FILE** **GENERATION** **OF** \"**hmist_64_64_RGB**.**csv**\" **WAS** **AN** **IMPORTANT** **STEP** **IN** **THE** **ABOVE** **MENTIONED** **JUPYTER**. **THIS** **CSV** **FILE** **CONTAINS** **THE** **RESHAPED** **PIXEL** **VALUES** **OF** **THE** **ORIGINAL** **DATASET**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q67fEqE3RSki",
        "colab_type": "text"
      },
      "source": [
        "**ABSTARCT** : To build a simple CNN model by the technique of sequential modelling by the means of keras library.\n",
        "\n",
        "To perform hyperparameter tuning by creating a kerasclassifier and by using the scikit learn library function of GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShKltHkKtsnG",
        "colab_type": "text"
      },
      "source": [
        "### **MODEL** **BUILDING** **AND** **VERIFICATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNauLrTmXX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing all the important libraries for model building \n",
        "# I will be using the keras library in order to build my first iteration of the CNN model\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D \n",
        "from keras.models import Sequential\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import plot_model\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV39-Ss3n7_I",
        "colab_type": "text"
      },
      "source": [
        "#### **LOADING** **THE** **DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Nk7FhAtLwX",
        "colab_type": "text"
      },
      "source": [
        "#### **NOTE**: **I** **will** **be** **uploading** **the** **resized** **image** **dataset** (**64x64x3**) **for** **building** **the** **baseline** **Convolutional** **Neural** **Network** **model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7NZtEacn0-z",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9a893f16-9317-4b0b-8a1d-4b4997225d0c"
      },
      "source": [
        " from google.colab import files \n",
        "  \n",
        "  \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0dff8d28-4b49-444d-89ef-955a5c5aa690\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0dff8d28-4b49-444d-89ef-955a5c5aa690\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving hmnist_64_64_RBG.csv to hmnist_64_64_RBG.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpbXJzp9ZNat",
        "colab_type": "text"
      },
      "source": [
        "#### **LOADING** **THE** **DATA** **IN** **A** **PANDAS** **DATAFRAME**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWmQZTtcXgew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_df = pd.read_csv('/content/hmnist_64_64_RBG.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSNo2JpfZtVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "ee6d9b6a-4e89-4756-d2b6-13ed7aaa5d23"
      },
      "source": [
        "cnn_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>12249</th>\n",
              "      <th>12250</th>\n",
              "      <th>12251</th>\n",
              "      <th>12252</th>\n",
              "      <th>12253</th>\n",
              "      <th>12254</th>\n",
              "      <th>12255</th>\n",
              "      <th>12256</th>\n",
              "      <th>12257</th>\n",
              "      <th>12258</th>\n",
              "      <th>12259</th>\n",
              "      <th>12260</th>\n",
              "      <th>12261</th>\n",
              "      <th>12262</th>\n",
              "      <th>12263</th>\n",
              "      <th>12264</th>\n",
              "      <th>12265</th>\n",
              "      <th>12266</th>\n",
              "      <th>12267</th>\n",
              "      <th>12268</th>\n",
              "      <th>12269</th>\n",
              "      <th>12270</th>\n",
              "      <th>12271</th>\n",
              "      <th>12272</th>\n",
              "      <th>12273</th>\n",
              "      <th>12274</th>\n",
              "      <th>12275</th>\n",
              "      <th>12276</th>\n",
              "      <th>12277</th>\n",
              "      <th>12278</th>\n",
              "      <th>12279</th>\n",
              "      <th>12280</th>\n",
              "      <th>12281</th>\n",
              "      <th>12282</th>\n",
              "      <th>12283</th>\n",
              "      <th>12284</th>\n",
              "      <th>12285</th>\n",
              "      <th>12286</th>\n",
              "      <th>12287</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "      <td>152</td>\n",
              "      <td>194</td>\n",
              "      <td>191</td>\n",
              "      <td>153</td>\n",
              "      <td>195</td>\n",
              "      <td>192</td>\n",
              "      <td>149</td>\n",
              "      <td>192</td>\n",
              "      <td>194</td>\n",
              "      <td>151</td>\n",
              "      <td>188</td>\n",
              "      <td>193</td>\n",
              "      <td>149</td>\n",
              "      <td>182</td>\n",
              "      <td>193</td>\n",
              "      <td>150</td>\n",
              "      <td>181</td>\n",
              "      <td>195</td>\n",
              "      <td>154</td>\n",
              "      <td>185</td>\n",
              "      <td>195</td>\n",
              "      <td>156</td>\n",
              "      <td>189</td>\n",
              "      <td>203</td>\n",
              "      <td>164</td>\n",
              "      <td>196</td>\n",
              "      <td>206</td>\n",
              "      <td>166</td>\n",
              "      <td>203</td>\n",
              "      <td>209</td>\n",
              "      <td>165</td>\n",
              "      <td>201</td>\n",
              "      <td>211</td>\n",
              "      <td>166</td>\n",
              "      <td>206</td>\n",
              "      <td>209</td>\n",
              "      <td>165</td>\n",
              "      <td>206</td>\n",
              "      <td>203</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>167</td>\n",
              "      <td>183</td>\n",
              "      <td>199</td>\n",
              "      <td>159</td>\n",
              "      <td>175</td>\n",
              "      <td>189</td>\n",
              "      <td>141</td>\n",
              "      <td>148</td>\n",
              "      <td>184</td>\n",
              "      <td>131</td>\n",
              "      <td>136</td>\n",
              "      <td>180</td>\n",
              "      <td>128</td>\n",
              "      <td>136</td>\n",
              "      <td>179</td>\n",
              "      <td>127</td>\n",
              "      <td>141</td>\n",
              "      <td>176</td>\n",
              "      <td>129</td>\n",
              "      <td>149</td>\n",
              "      <td>175</td>\n",
              "      <td>127</td>\n",
              "      <td>145</td>\n",
              "      <td>179</td>\n",
              "      <td>136</td>\n",
              "      <td>157</td>\n",
              "      <td>182</td>\n",
              "      <td>146</td>\n",
              "      <td>164</td>\n",
              "      <td>185</td>\n",
              "      <td>154</td>\n",
              "      <td>180</td>\n",
              "      <td>186</td>\n",
              "      <td>156</td>\n",
              "      <td>184</td>\n",
              "      <td>182</td>\n",
              "      <td>152</td>\n",
              "      <td>173</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>24</td>\n",
              "      <td>46</td>\n",
              "      <td>61</td>\n",
              "      <td>44</td>\n",
              "      <td>70</td>\n",
              "      <td>90</td>\n",
              "      <td>66</td>\n",
              "      <td>97</td>\n",
              "      <td>111</td>\n",
              "      <td>83</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>98</td>\n",
              "      <td>129</td>\n",
              "      <td>144</td>\n",
              "      <td>112</td>\n",
              "      <td>141</td>\n",
              "      <td>161</td>\n",
              "      <td>131</td>\n",
              "      <td>159</td>\n",
              "      <td>169</td>\n",
              "      <td>138</td>\n",
              "      <td>165</td>\n",
              "      <td>171</td>\n",
              "      <td>135</td>\n",
              "      <td>159</td>\n",
              "      <td>173</td>\n",
              "      <td>135</td>\n",
              "      <td>156</td>\n",
              "      <td>178</td>\n",
              "      <td>138</td>\n",
              "      <td>164</td>\n",
              "      <td>178</td>\n",
              "      <td>...</td>\n",
              "      <td>176</td>\n",
              "      <td>132</td>\n",
              "      <td>147</td>\n",
              "      <td>163</td>\n",
              "      <td>121</td>\n",
              "      <td>129</td>\n",
              "      <td>143</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>129</td>\n",
              "      <td>89</td>\n",
              "      <td>90</td>\n",
              "      <td>111</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>92</td>\n",
              "      <td>60</td>\n",
              "      <td>64</td>\n",
              "      <td>69</td>\n",
              "      <td>46</td>\n",
              "      <td>56</td>\n",
              "      <td>44</td>\n",
              "      <td>27</td>\n",
              "      <td>43</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>30</td>\n",
              "      <td>26</td>\n",
              "      <td>15</td>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "      <td>15</td>\n",
              "      <td>28</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>185</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>192</td>\n",
              "      <td>136</td>\n",
              "      <td>151</td>\n",
              "      <td>198</td>\n",
              "      <td>142</td>\n",
              "      <td>156</td>\n",
              "      <td>198</td>\n",
              "      <td>140</td>\n",
              "      <td>154</td>\n",
              "      <td>199</td>\n",
              "      <td>141</td>\n",
              "      <td>158</td>\n",
              "      <td>199</td>\n",
              "      <td>141</td>\n",
              "      <td>159</td>\n",
              "      <td>205</td>\n",
              "      <td>147</td>\n",
              "      <td>162</td>\n",
              "      <td>205</td>\n",
              "      <td>151</td>\n",
              "      <td>167</td>\n",
              "      <td>208</td>\n",
              "      <td>154</td>\n",
              "      <td>171</td>\n",
              "      <td>207</td>\n",
              "      <td>147</td>\n",
              "      <td>161</td>\n",
              "      <td>204</td>\n",
              "      <td>146</td>\n",
              "      <td>153</td>\n",
              "      <td>207</td>\n",
              "      <td>154</td>\n",
              "      <td>161</td>\n",
              "      <td>209</td>\n",
              "      <td>156</td>\n",
              "      <td>163</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>199</td>\n",
              "      <td>156</td>\n",
              "      <td>175</td>\n",
              "      <td>190</td>\n",
              "      <td>147</td>\n",
              "      <td>171</td>\n",
              "      <td>194</td>\n",
              "      <td>154</td>\n",
              "      <td>183</td>\n",
              "      <td>197</td>\n",
              "      <td>152</td>\n",
              "      <td>172</td>\n",
              "      <td>175</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>160</td>\n",
              "      <td>117</td>\n",
              "      <td>132</td>\n",
              "      <td>163</td>\n",
              "      <td>127</td>\n",
              "      <td>141</td>\n",
              "      <td>161</td>\n",
              "      <td>128</td>\n",
              "      <td>140</td>\n",
              "      <td>161</td>\n",
              "      <td>128</td>\n",
              "      <td>144</td>\n",
              "      <td>155</td>\n",
              "      <td>122</td>\n",
              "      <td>139</td>\n",
              "      <td>152</td>\n",
              "      <td>120</td>\n",
              "      <td>138</td>\n",
              "      <td>144</td>\n",
              "      <td>113</td>\n",
              "      <td>123</td>\n",
              "      <td>115</td>\n",
              "      <td>81</td>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>36</td>\n",
              "      <td>19</td>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>38</td>\n",
              "      <td>50</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>71</td>\n",
              "      <td>111</td>\n",
              "      <td>71</td>\n",
              "      <td>87</td>\n",
              "      <td>130</td>\n",
              "      <td>91</td>\n",
              "      <td>106</td>\n",
              "      <td>150</td>\n",
              "      <td>114</td>\n",
              "      <td>129</td>\n",
              "      <td>160</td>\n",
              "      <td>116</td>\n",
              "      <td>124</td>\n",
              "      <td>167</td>\n",
              "      <td>110</td>\n",
              "      <td>111</td>\n",
              "      <td>168</td>\n",
              "      <td>100</td>\n",
              "      <td>101</td>\n",
              "      <td>176</td>\n",
              "      <td>110</td>\n",
              "      <td>116</td>\n",
              "      <td>184</td>\n",
              "      <td>131</td>\n",
              "      <td>144</td>\n",
              "      <td>191</td>\n",
              "      <td>141</td>\n",
              "      <td>152</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>154</td>\n",
              "      <td>124</td>\n",
              "      <td>138</td>\n",
              "      <td>143</td>\n",
              "      <td>111</td>\n",
              "      <td>126</td>\n",
              "      <td>129</td>\n",
              "      <td>100</td>\n",
              "      <td>111</td>\n",
              "      <td>102</td>\n",
              "      <td>74</td>\n",
              "      <td>80</td>\n",
              "      <td>94</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>74</td>\n",
              "      <td>47</td>\n",
              "      <td>61</td>\n",
              "      <td>52</td>\n",
              "      <td>32</td>\n",
              "      <td>45</td>\n",
              "      <td>33</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>17</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>138</td>\n",
              "      <td>94</td>\n",
              "      <td>117</td>\n",
              "      <td>158</td>\n",
              "      <td>113</td>\n",
              "      <td>138</td>\n",
              "      <td>178</td>\n",
              "      <td>133</td>\n",
              "      <td>161</td>\n",
              "      <td>191</td>\n",
              "      <td>143</td>\n",
              "      <td>172</td>\n",
              "      <td>202</td>\n",
              "      <td>150</td>\n",
              "      <td>173</td>\n",
              "      <td>212</td>\n",
              "      <td>160</td>\n",
              "      <td>185</td>\n",
              "      <td>216</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>222</td>\n",
              "      <td>175</td>\n",
              "      <td>209</td>\n",
              "      <td>227</td>\n",
              "      <td>183</td>\n",
              "      <td>219</td>\n",
              "      <td>229</td>\n",
              "      <td>183</td>\n",
              "      <td>216</td>\n",
              "      <td>232</td>\n",
              "      <td>188</td>\n",
              "      <td>221</td>\n",
              "      <td>234</td>\n",
              "      <td>193</td>\n",
              "      <td>222</td>\n",
              "      <td>234</td>\n",
              "      <td>191</td>\n",
              "      <td>218</td>\n",
              "      <td>235</td>\n",
              "      <td>...</td>\n",
              "      <td>221</td>\n",
              "      <td>169</td>\n",
              "      <td>202</td>\n",
              "      <td>226</td>\n",
              "      <td>167</td>\n",
              "      <td>201</td>\n",
              "      <td>226</td>\n",
              "      <td>164</td>\n",
              "      <td>197</td>\n",
              "      <td>224</td>\n",
              "      <td>176</td>\n",
              "      <td>203</td>\n",
              "      <td>224</td>\n",
              "      <td>178</td>\n",
              "      <td>206</td>\n",
              "      <td>222</td>\n",
              "      <td>181</td>\n",
              "      <td>206</td>\n",
              "      <td>213</td>\n",
              "      <td>170</td>\n",
              "      <td>191</td>\n",
              "      <td>200</td>\n",
              "      <td>155</td>\n",
              "      <td>177</td>\n",
              "      <td>187</td>\n",
              "      <td>148</td>\n",
              "      <td>164</td>\n",
              "      <td>164</td>\n",
              "      <td>128</td>\n",
              "      <td>140</td>\n",
              "      <td>140</td>\n",
              "      <td>106</td>\n",
              "      <td>118</td>\n",
              "      <td>108</td>\n",
              "      <td>77</td>\n",
              "      <td>92</td>\n",
              "      <td>67</td>\n",
              "      <td>40</td>\n",
              "      <td>55</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12289 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5  ...  12283  12284  12285  12286  12287  label\n",
              "0  191  152  194  191  153  195  ...    156    184    182    152    173      2\n",
              "1   24   13   23   24   14   28  ...     15     28     24     13     25      2\n",
              "2  185  129  140  192  136  151  ...    113    123    115     81     84      2\n",
              "3   24   11   19   36   19   30  ...     12     16     24      9     14      2\n",
              "4  138   94  117  158  113  138  ...     77     92     67     40     55      2\n",
              "\n",
              "[5 rows x 12289 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy5gjCxM65Wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86d0a8fc-d870-4c25-d0ad-d14e38bb0e3d"
      },
      "source": [
        "# Checking the shape of the dataset\n",
        "cnn_df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10015, 12289)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbQZ6TXd7A6V",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : It has a total of 10015 rows and 12289 columns in the dataset. This rows and columns are nothing but the pixel values of every resized image in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdwGaGwVaCDZ",
        "colab_type": "text"
      },
      "source": [
        "#### **Dropping** **the** **column** \"**label**\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVl_YDXoZ35t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping the 'label' column and then converting the dataframe into an array value\n",
        "cnn_drop = cnn_df.drop(\"label\", axis=1)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5NjSta_9iQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "2fbc351f-a99e-40ea-c425-d5b3460377ad"
      },
      "source": [
        "cnn_drop.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>12248</th>\n",
              "      <th>12249</th>\n",
              "      <th>12250</th>\n",
              "      <th>12251</th>\n",
              "      <th>12252</th>\n",
              "      <th>12253</th>\n",
              "      <th>12254</th>\n",
              "      <th>12255</th>\n",
              "      <th>12256</th>\n",
              "      <th>12257</th>\n",
              "      <th>12258</th>\n",
              "      <th>12259</th>\n",
              "      <th>12260</th>\n",
              "      <th>12261</th>\n",
              "      <th>12262</th>\n",
              "      <th>12263</th>\n",
              "      <th>12264</th>\n",
              "      <th>12265</th>\n",
              "      <th>12266</th>\n",
              "      <th>12267</th>\n",
              "      <th>12268</th>\n",
              "      <th>12269</th>\n",
              "      <th>12270</th>\n",
              "      <th>12271</th>\n",
              "      <th>12272</th>\n",
              "      <th>12273</th>\n",
              "      <th>12274</th>\n",
              "      <th>12275</th>\n",
              "      <th>12276</th>\n",
              "      <th>12277</th>\n",
              "      <th>12278</th>\n",
              "      <th>12279</th>\n",
              "      <th>12280</th>\n",
              "      <th>12281</th>\n",
              "      <th>12282</th>\n",
              "      <th>12283</th>\n",
              "      <th>12284</th>\n",
              "      <th>12285</th>\n",
              "      <th>12286</th>\n",
              "      <th>12287</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "      <td>152</td>\n",
              "      <td>194</td>\n",
              "      <td>191</td>\n",
              "      <td>153</td>\n",
              "      <td>195</td>\n",
              "      <td>192</td>\n",
              "      <td>149</td>\n",
              "      <td>192</td>\n",
              "      <td>194</td>\n",
              "      <td>151</td>\n",
              "      <td>188</td>\n",
              "      <td>193</td>\n",
              "      <td>149</td>\n",
              "      <td>182</td>\n",
              "      <td>193</td>\n",
              "      <td>150</td>\n",
              "      <td>181</td>\n",
              "      <td>195</td>\n",
              "      <td>154</td>\n",
              "      <td>185</td>\n",
              "      <td>195</td>\n",
              "      <td>156</td>\n",
              "      <td>189</td>\n",
              "      <td>203</td>\n",
              "      <td>164</td>\n",
              "      <td>196</td>\n",
              "      <td>206</td>\n",
              "      <td>166</td>\n",
              "      <td>203</td>\n",
              "      <td>209</td>\n",
              "      <td>165</td>\n",
              "      <td>201</td>\n",
              "      <td>211</td>\n",
              "      <td>166</td>\n",
              "      <td>206</td>\n",
              "      <td>209</td>\n",
              "      <td>165</td>\n",
              "      <td>206</td>\n",
              "      <td>203</td>\n",
              "      <td>...</td>\n",
              "      <td>179</td>\n",
              "      <td>202</td>\n",
              "      <td>167</td>\n",
              "      <td>183</td>\n",
              "      <td>199</td>\n",
              "      <td>159</td>\n",
              "      <td>175</td>\n",
              "      <td>189</td>\n",
              "      <td>141</td>\n",
              "      <td>148</td>\n",
              "      <td>184</td>\n",
              "      <td>131</td>\n",
              "      <td>136</td>\n",
              "      <td>180</td>\n",
              "      <td>128</td>\n",
              "      <td>136</td>\n",
              "      <td>179</td>\n",
              "      <td>127</td>\n",
              "      <td>141</td>\n",
              "      <td>176</td>\n",
              "      <td>129</td>\n",
              "      <td>149</td>\n",
              "      <td>175</td>\n",
              "      <td>127</td>\n",
              "      <td>145</td>\n",
              "      <td>179</td>\n",
              "      <td>136</td>\n",
              "      <td>157</td>\n",
              "      <td>182</td>\n",
              "      <td>146</td>\n",
              "      <td>164</td>\n",
              "      <td>185</td>\n",
              "      <td>154</td>\n",
              "      <td>180</td>\n",
              "      <td>186</td>\n",
              "      <td>156</td>\n",
              "      <td>184</td>\n",
              "      <td>182</td>\n",
              "      <td>152</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>24</td>\n",
              "      <td>46</td>\n",
              "      <td>61</td>\n",
              "      <td>44</td>\n",
              "      <td>70</td>\n",
              "      <td>90</td>\n",
              "      <td>66</td>\n",
              "      <td>97</td>\n",
              "      <td>111</td>\n",
              "      <td>83</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>98</td>\n",
              "      <td>129</td>\n",
              "      <td>144</td>\n",
              "      <td>112</td>\n",
              "      <td>141</td>\n",
              "      <td>161</td>\n",
              "      <td>131</td>\n",
              "      <td>159</td>\n",
              "      <td>169</td>\n",
              "      <td>138</td>\n",
              "      <td>165</td>\n",
              "      <td>171</td>\n",
              "      <td>135</td>\n",
              "      <td>159</td>\n",
              "      <td>173</td>\n",
              "      <td>135</td>\n",
              "      <td>156</td>\n",
              "      <td>178</td>\n",
              "      <td>138</td>\n",
              "      <td>164</td>\n",
              "      <td>178</td>\n",
              "      <td>...</td>\n",
              "      <td>159</td>\n",
              "      <td>176</td>\n",
              "      <td>132</td>\n",
              "      <td>147</td>\n",
              "      <td>163</td>\n",
              "      <td>121</td>\n",
              "      <td>129</td>\n",
              "      <td>143</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>129</td>\n",
              "      <td>89</td>\n",
              "      <td>90</td>\n",
              "      <td>111</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>92</td>\n",
              "      <td>60</td>\n",
              "      <td>64</td>\n",
              "      <td>69</td>\n",
              "      <td>46</td>\n",
              "      <td>56</td>\n",
              "      <td>44</td>\n",
              "      <td>27</td>\n",
              "      <td>43</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>30</td>\n",
              "      <td>26</td>\n",
              "      <td>15</td>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "      <td>15</td>\n",
              "      <td>28</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>185</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>192</td>\n",
              "      <td>136</td>\n",
              "      <td>151</td>\n",
              "      <td>198</td>\n",
              "      <td>142</td>\n",
              "      <td>156</td>\n",
              "      <td>198</td>\n",
              "      <td>140</td>\n",
              "      <td>154</td>\n",
              "      <td>199</td>\n",
              "      <td>141</td>\n",
              "      <td>158</td>\n",
              "      <td>199</td>\n",
              "      <td>141</td>\n",
              "      <td>159</td>\n",
              "      <td>205</td>\n",
              "      <td>147</td>\n",
              "      <td>162</td>\n",
              "      <td>205</td>\n",
              "      <td>151</td>\n",
              "      <td>167</td>\n",
              "      <td>208</td>\n",
              "      <td>154</td>\n",
              "      <td>171</td>\n",
              "      <td>207</td>\n",
              "      <td>147</td>\n",
              "      <td>161</td>\n",
              "      <td>204</td>\n",
              "      <td>146</td>\n",
              "      <td>153</td>\n",
              "      <td>207</td>\n",
              "      <td>154</td>\n",
              "      <td>161</td>\n",
              "      <td>209</td>\n",
              "      <td>156</td>\n",
              "      <td>163</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>179</td>\n",
              "      <td>199</td>\n",
              "      <td>156</td>\n",
              "      <td>175</td>\n",
              "      <td>190</td>\n",
              "      <td>147</td>\n",
              "      <td>171</td>\n",
              "      <td>194</td>\n",
              "      <td>154</td>\n",
              "      <td>183</td>\n",
              "      <td>197</td>\n",
              "      <td>152</td>\n",
              "      <td>172</td>\n",
              "      <td>175</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>160</td>\n",
              "      <td>117</td>\n",
              "      <td>132</td>\n",
              "      <td>163</td>\n",
              "      <td>127</td>\n",
              "      <td>141</td>\n",
              "      <td>161</td>\n",
              "      <td>128</td>\n",
              "      <td>140</td>\n",
              "      <td>161</td>\n",
              "      <td>128</td>\n",
              "      <td>144</td>\n",
              "      <td>155</td>\n",
              "      <td>122</td>\n",
              "      <td>139</td>\n",
              "      <td>152</td>\n",
              "      <td>120</td>\n",
              "      <td>138</td>\n",
              "      <td>144</td>\n",
              "      <td>113</td>\n",
              "      <td>123</td>\n",
              "      <td>115</td>\n",
              "      <td>81</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>36</td>\n",
              "      <td>19</td>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>38</td>\n",
              "      <td>50</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>71</td>\n",
              "      <td>111</td>\n",
              "      <td>71</td>\n",
              "      <td>87</td>\n",
              "      <td>130</td>\n",
              "      <td>91</td>\n",
              "      <td>106</td>\n",
              "      <td>150</td>\n",
              "      <td>114</td>\n",
              "      <td>129</td>\n",
              "      <td>160</td>\n",
              "      <td>116</td>\n",
              "      <td>124</td>\n",
              "      <td>167</td>\n",
              "      <td>110</td>\n",
              "      <td>111</td>\n",
              "      <td>168</td>\n",
              "      <td>100</td>\n",
              "      <td>101</td>\n",
              "      <td>176</td>\n",
              "      <td>110</td>\n",
              "      <td>116</td>\n",
              "      <td>184</td>\n",
              "      <td>131</td>\n",
              "      <td>144</td>\n",
              "      <td>191</td>\n",
              "      <td>141</td>\n",
              "      <td>152</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>162</td>\n",
              "      <td>154</td>\n",
              "      <td>124</td>\n",
              "      <td>138</td>\n",
              "      <td>143</td>\n",
              "      <td>111</td>\n",
              "      <td>126</td>\n",
              "      <td>129</td>\n",
              "      <td>100</td>\n",
              "      <td>111</td>\n",
              "      <td>102</td>\n",
              "      <td>74</td>\n",
              "      <td>80</td>\n",
              "      <td>94</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>74</td>\n",
              "      <td>47</td>\n",
              "      <td>61</td>\n",
              "      <td>52</td>\n",
              "      <td>32</td>\n",
              "      <td>45</td>\n",
              "      <td>33</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>17</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>138</td>\n",
              "      <td>94</td>\n",
              "      <td>117</td>\n",
              "      <td>158</td>\n",
              "      <td>113</td>\n",
              "      <td>138</td>\n",
              "      <td>178</td>\n",
              "      <td>133</td>\n",
              "      <td>161</td>\n",
              "      <td>191</td>\n",
              "      <td>143</td>\n",
              "      <td>172</td>\n",
              "      <td>202</td>\n",
              "      <td>150</td>\n",
              "      <td>173</td>\n",
              "      <td>212</td>\n",
              "      <td>160</td>\n",
              "      <td>185</td>\n",
              "      <td>216</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>222</td>\n",
              "      <td>175</td>\n",
              "      <td>209</td>\n",
              "      <td>227</td>\n",
              "      <td>183</td>\n",
              "      <td>219</td>\n",
              "      <td>229</td>\n",
              "      <td>183</td>\n",
              "      <td>216</td>\n",
              "      <td>232</td>\n",
              "      <td>188</td>\n",
              "      <td>221</td>\n",
              "      <td>234</td>\n",
              "      <td>193</td>\n",
              "      <td>222</td>\n",
              "      <td>234</td>\n",
              "      <td>191</td>\n",
              "      <td>218</td>\n",
              "      <td>235</td>\n",
              "      <td>...</td>\n",
              "      <td>209</td>\n",
              "      <td>221</td>\n",
              "      <td>169</td>\n",
              "      <td>202</td>\n",
              "      <td>226</td>\n",
              "      <td>167</td>\n",
              "      <td>201</td>\n",
              "      <td>226</td>\n",
              "      <td>164</td>\n",
              "      <td>197</td>\n",
              "      <td>224</td>\n",
              "      <td>176</td>\n",
              "      <td>203</td>\n",
              "      <td>224</td>\n",
              "      <td>178</td>\n",
              "      <td>206</td>\n",
              "      <td>222</td>\n",
              "      <td>181</td>\n",
              "      <td>206</td>\n",
              "      <td>213</td>\n",
              "      <td>170</td>\n",
              "      <td>191</td>\n",
              "      <td>200</td>\n",
              "      <td>155</td>\n",
              "      <td>177</td>\n",
              "      <td>187</td>\n",
              "      <td>148</td>\n",
              "      <td>164</td>\n",
              "      <td>164</td>\n",
              "      <td>128</td>\n",
              "      <td>140</td>\n",
              "      <td>140</td>\n",
              "      <td>106</td>\n",
              "      <td>118</td>\n",
              "      <td>108</td>\n",
              "      <td>77</td>\n",
              "      <td>92</td>\n",
              "      <td>67</td>\n",
              "      <td>40</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12288 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5  ...  12282  12283  12284  12285  12286  12287\n",
              "0  191  152  194  191  153  195  ...    186    156    184    182    152    173\n",
              "1   24   13   23   24   14   28  ...     27     15     28     24     13     25\n",
              "2  185  129  140  192  136  151  ...    144    113    123    115     81     84\n",
              "3   24   11   19   36   19   30  ...     25     12     16     24      9     14\n",
              "4  138   94  117  158  113  138  ...    108     77     92     67     40     55\n",
              "\n",
              "[5 rows x 12288 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVCZJvtF-nPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = cnn_drop.to_numpy()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81wc6lTe_Bnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9c0dc6f-b46a-4e7e-8e18-1bab9025d9c7"
      },
      "source": [
        "# Checking the shape of the array\n",
        "X.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10015, 12288)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pyidSeICDbe",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : The array 'X' has a total of 10015 rows and 12288 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UckOvBAD_vwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Storing the 'label' column values in a different variable i.e. 'label'\n",
        "label = cnn_df[\"label\"].values"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb8sCxvABS0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9d0a372-507b-446d-dd2b-08ceedaa5c44"
      },
      "source": [
        "# Checking the shape of 'label' column\n",
        "label.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10015,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mhf7IRnBaoT",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : One can say that 'label' consists of all 10015 rows of the dataset and since its a single column, the column count value is not highlighted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7XHJLehFqfM",
        "colab_type": "text"
      },
      "source": [
        "### **DATA** **PREPROCESSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EUK1TxGFydP",
        "colab_type": "text"
      },
      "source": [
        "##### **SCALING** **AND** **SPLITTING** **THE** **DATA** **INTO** **TRAIN** **TEST** **AND** **VALIDATION** **DATASETS** **FOR** **FURTHER** **MODEL** **CREATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jztAKllhFxRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling (normalization) of the dataset\n",
        "X_mean = np.mean(X) # calculating the mean of the numpy array\n",
        "X_std = np.std(X) # Calculating the standard deviation of the numpy array\n",
        "\n",
        "X = (X - X_mean)/X_std # Standardizing/ Normalizing the numpy array"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxzzpijWHD6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into train and test sets\n",
        "\n",
        "# Here I will be considering the entire dataset as the training data hence taking the complete dataset 'X' into consideration\n",
        "# Also only 10% of the dataset will be used as the testing dataset. Hence the test_size has been mentioned as 0.1 and a random state of '0' in order to \n",
        "# to avoid random splitting of the dataset.\n",
        "\n",
        "X_train_orig, X_test, y_train_orig, y_test = train_test_split(X, label, test_size=0.1,random_state=0)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IloPytZ5YPAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "862a7622-5882-405b-ba0b-5793ab573c50"
      },
      "source": [
        "# Checking the shape of the two splits\n",
        "\n",
        "X_train_orig.shape, X_test.shape, y_train_orig.shape, y_test.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9013, 12288), (1002, 12288), (9013,), (1002,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4zoN-0WYY0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into train and validation dataset from already splitted train dataset in the previous set\n",
        "\n",
        "# Here I will be considering 20% of the data as the validation set data hence, the test size is set to 0.2, with a random state of 1.\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv-5X_4dd-me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4d6c6ff-4dcd-4000-f540-4ca5fef1d65f"
      },
      "source": [
        "# Checking the shape of final train and validation sets\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7210, 12288), (1803, 12288), (7210,), (1803,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxEYGCATqTxh",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : From the above command, the exact shape of the train,test,validation dataset confirms that there are 7210 rows and 12288 columns in the input training dataset, 1803 rows in the input validation set and 12288 columns and finally 7210 rows and 1803 rows in the output validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt8jIM24J99o",
        "colab_type": "text"
      },
      "source": [
        "#### **RESHAPING** **THE** **DATA** **TO** **BUILD** **THE** **MODEL** **FURTHER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aceszh-UFFNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], *(64, 64, 3))\n",
        "X_val = X_val.reshape(X_val.shape[0], *(64, 64, 3))\n",
        "X_test = X_test.reshape(X_test.shape[0], *(64, 64, 3))\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RndBpVVKVCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d21c7e49-e6b9-4dca-8739-8b44c6365384"
      },
      "source": [
        "# checking the shape of each input training,validation and test datasets\n",
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7210, 64, 64, 3), (1803, 64, 64, 3), (1002, 64, 64, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-30gLXzgLNYb",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : One can see that the dataset has been reshaped in the form of 64x64x3 where 64x64 is the pixel size and 3 is the RGB information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF3-iKqTKiDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "948765ba-fa94-45e3-8a72-f32af574e8a3"
      },
      "source": [
        "# checking the shape of the output training dataset\n",
        "y_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7210,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMp-28p9Li0d",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : The output training set consists a total of 7210 rows and just a single column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_CkGHP8LtrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changing the output training, validation and test set data into matrix form\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwK5TTGiNC7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf46a4c4-54f8-42a4-9944-f79cc7be4ddb"
      },
      "source": [
        "# Checking the shape of output training, testing and validation datasets\n",
        "\n",
        "y_train.shape, y_val.shape, y_test.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7210, 7), (1803, 7), (1002, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNnfHODCTB10",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : Finally the output training, validation and test datasets consists of 7210 rows, 1803 rows, 1002 rows respectively with every dataset consisting of 7 columns each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zWxaxYSmOXM",
        "colab_type": "text"
      },
      "source": [
        "###**TO** **BUILD** **THE** **CNN** **MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG7DKeD7qdHY",
        "colab_type": "text"
      },
      "source": [
        "### **Steps** **involved** **to** **create** **a** **CNN** **model** **are** **as** **follows** :\n",
        "\n",
        "**NOTE** : I used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n",
        "\n",
        "**Q**. Why I used the Keras Sequential API?\n",
        "\n",
        "Ans : To answer this question, Keras Sequential API is the most popular, highest level API which is extremely simple, concise and readable. It has a simple network which is easy to debug as well.\n",
        "\n",
        "The basic architecture of a CNN consists of the following :\n",
        "\n",
        "- The first is the **convolutional** (**Conv2D**) **layer**. It is like a set of learnable filters. I chose to set **16** filters for the  first conv2D layer, **32** filters for the second conv2D layer and **64** filters for the  last one.\n",
        "\n",
        "- Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. \n",
        "\n",
        "- The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n",
        "\n",
        "- The CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n",
        "\n",
        "- The second important layer in CNN is the **pooling** (**MaxPool2D**) **layer**. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting.\n",
        "\n",
        "- We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is **high**, more the downsampling is important.\n",
        "\n",
        "- Combining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n",
        "\n",
        "- **Dropout** is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n",
        "\n",
        "- '**relu**' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network.\n",
        "\n",
        "- The **Flatten** layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.\n",
        "\n",
        "- In the end i used the features in a fully-connected (Dense) layer which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-uoWofE5y9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing the KerasClassifier from the scikit learn wrapper class\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP9vzCq3NvJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "a67d57ac-7583-4522-915a-f12257a7e173"
      },
      "source": [
        "\n",
        "  \n",
        "# Our input feature map is 64x64x3: 64x64 for the image pixels, and 3 for\n",
        "# the three color channels: R, G, and B\n",
        "input_shape = (64,64,3)\n",
        "num_classes = 7\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First convolution extracts 16 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
        "model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "# Second convolution extracts 32 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same'))\n",
        "model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "\n",
        "# Third convolution extracts 64 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='Same'))\n",
        "model.add(MaxPool2D(pool_size= (2, 2)))\n",
        "\n",
        "# Flatten feature map to a 1-dim tensor\n",
        "model.add(Flatten())\n",
        "\n",
        "# Create a fully connected layer with ReLU activation and 512 hidden units (neurons)\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Adding the output layer with the sigmoid function for classification\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Adding the summary of the model\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 2,124,839\n",
            "Trainable params: 2,124,839\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnJEA5n5H1Kg",
        "colab_type": "text"
      },
      "source": [
        "#### **SETTING** **THE** **OPTIMIZER** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw82tKrCIWkg",
        "colab_type": "text"
      },
      "source": [
        "Once our layers are added to the model, we need to set up a score function, a loss function and an optimisation algorithm. We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\". The most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons) in order to minimise the loss.\n",
        "\n",
        "I chose Adam optimizer because it combines the advantages of two other extensions of stochastic gradient descent. \n",
        "\n",
        "Specifically:\n",
        "\n",
        "Adaptive Gradient Algorithm (AdaGrad) that maintains a per-parameter learning rate that improves performance on problems with sparse gradients (e.g. natural language and computer vision problems).\n",
        "\n",
        "Root Mean Square Propagation (RMSProp) that also maintains per-parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight (e.g. how quickly it is changing). This means the algorithm does well on online and non-stationary problems (e.g. noisy).\n",
        "\n",
        "Adam realizes the benefits of both AdaGrad and RMSProp.\n",
        "\n",
        "Adam is a popular algorithm in the field of deep learning because it achieves good results fast.\n",
        "\n",
        "The metric function \"accuracy\" is used is to evaluate the performance our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgqfbi2G4uKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the optimizer\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RagNk2FK1Hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR1Ck2hkUp4a",
        "colab_type": "text"
      },
      "source": [
        "In order to make the optimizer converge faster and closest to the global minimum of the loss function, i used an annealing method of the learning rate (LR).\n",
        "\n",
        "The LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima.\n",
        "\n",
        "Its better to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function.\n",
        "\n",
        "To keep the advantage of the fast computation time with a high LR, i decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).\n",
        "\n",
        "With the ReduceLROnPlateau function from Keras.callbacks, i choose to reduce the LR by half if the accuracy is not improved after 3 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEZpwZpEVAP-",
        "colab_type": "text"
      },
      "source": [
        "### **DATA** **AUGMENTATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHH1Mm4qVR2t",
        "colab_type": "text"
      },
      "source": [
        "- It is the optional step. In order to avoid overfitting problem, we need to expand artificially our HAM 10000 dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations\n",
        "\n",
        "- Approaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\n",
        "\n",
        "- By applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqvQ5qrqVJIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,\n",
        "                             shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_datagen.fit(X_val)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhCvwcDeAh-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7OcUOcrAq5M",
        "colab_type": "text"
      },
      "source": [
        "**MODEL** **FITTING**\n",
        "\n",
        "This step finally I fit the model into x_train, y_train. In this step I have choosen batch size of 10 and 50 epochs as small as your batch size will be more efficiently your model will train and I have choosen 50 epochs to give the model sufficient epochs to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIOyDYB5OzOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2a72cc8-3d32-409d-fbdc-b18030aa82ce"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "history = model.fit_generator(train_datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-33-064a233de445>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 1.0125 - accuracy: 0.6576WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 348ms/step - loss: 1.0125 - accuracy: 0.6576 - val_loss: 0.8982 - val_accuracy: 0.6622\n",
            "Epoch 2/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.8599 - accuracy: 0.6847WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 345ms/step - loss: 0.8599 - accuracy: 0.6847 - val_loss: 0.8468 - val_accuracy: 0.7060\n",
            "Epoch 3/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.8050 - accuracy: 0.7022WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 347ms/step - loss: 0.8050 - accuracy: 0.7022 - val_loss: 0.8079 - val_accuracy: 0.7105\n",
            "Epoch 4/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.7718 - accuracy: 0.7154WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 344ms/step - loss: 0.7718 - accuracy: 0.7154 - val_loss: 0.7396 - val_accuracy: 0.7221\n",
            "Epoch 5/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.7507 - accuracy: 0.7257WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 345ms/step - loss: 0.7507 - accuracy: 0.7257 - val_loss: 0.7750 - val_accuracy: 0.6983\n",
            "Epoch 6/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.7429 - accuracy: 0.7235WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 345ms/step - loss: 0.7429 - accuracy: 0.7235 - val_loss: 0.7349 - val_accuracy: 0.7188\n",
            "Epoch 7/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.7275 - accuracy: 0.7309WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 345ms/step - loss: 0.7275 - accuracy: 0.7309 - val_loss: 0.6992 - val_accuracy: 0.7338\n",
            "Epoch 8/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.7331WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 347ms/step - loss: 0.7137 - accuracy: 0.7331 - val_loss: 0.7328 - val_accuracy: 0.7227\n",
            "Epoch 9/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6985 - accuracy: 0.7397WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 343ms/step - loss: 0.6985 - accuracy: 0.7397 - val_loss: 0.6889 - val_accuracy: 0.7460\n",
            "Epoch 10/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.7467WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 345ms/step - loss: 0.6872 - accuracy: 0.7467 - val_loss: 0.7095 - val_accuracy: 0.7321\n",
            "Epoch 11/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6785 - accuracy: 0.7470WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 344ms/step - loss: 0.6785 - accuracy: 0.7470 - val_loss: 0.6712 - val_accuracy: 0.7471\n",
            "Epoch 12/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6743 - accuracy: 0.7443WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 342ms/step - loss: 0.6743 - accuracy: 0.7443 - val_loss: 0.7116 - val_accuracy: 0.7465\n",
            "Epoch 13/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.7526WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 342ms/step - loss: 0.6522 - accuracy: 0.7526 - val_loss: 0.6685 - val_accuracy: 0.7476\n",
            "Epoch 14/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.7586WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 345ms/step - loss: 0.6497 - accuracy: 0.7586 - val_loss: 0.6488 - val_accuracy: 0.7549\n",
            "Epoch 15/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.7597WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 345ms/step - loss: 0.6441 - accuracy: 0.7597 - val_loss: 0.6753 - val_accuracy: 0.7443\n",
            "Epoch 16/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.7629WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 344ms/step - loss: 0.6324 - accuracy: 0.7629 - val_loss: 0.6495 - val_accuracy: 0.7676\n",
            "Epoch 17/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.7663WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 343ms/step - loss: 0.6406 - accuracy: 0.7663 - val_loss: 0.6452 - val_accuracy: 0.7598\n",
            "Epoch 18/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.7655WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 344ms/step - loss: 0.6363 - accuracy: 0.7655 - val_loss: 0.6489 - val_accuracy: 0.7582\n",
            "Epoch 19/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.7719WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 343ms/step - loss: 0.6193 - accuracy: 0.7719 - val_loss: 0.6462 - val_accuracy: 0.7504\n",
            "Epoch 20/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.7641WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 39s 345ms/step - loss: 0.6300 - accuracy: 0.7641 - val_loss: 0.6378 - val_accuracy: 0.7621\n",
            "Epoch 21/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6082 - accuracy: 0.7764WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 342ms/step - loss: 0.6082 - accuracy: 0.7764 - val_loss: 0.6315 - val_accuracy: 0.7598\n",
            "Epoch 22/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6114 - accuracy: 0.7701WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 343ms/step - loss: 0.6114 - accuracy: 0.7701 - val_loss: 0.6346 - val_accuracy: 0.7671\n",
            "Epoch 23/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7803WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 341ms/step - loss: 0.6042 - accuracy: 0.7803 - val_loss: 0.6525 - val_accuracy: 0.7582\n",
            "Epoch 24/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.7800WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 341ms/step - loss: 0.5968 - accuracy: 0.7800 - val_loss: 0.6457 - val_accuracy: 0.7587\n",
            "Epoch 25/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.5912 - accuracy: 0.7788WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 340ms/step - loss: 0.5912 - accuracy: 0.7788 - val_loss: 0.6370 - val_accuracy: 0.7715\n",
            "Epoch 26/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.5879 - accuracy: 0.7809WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 341ms/step - loss: 0.5879 - accuracy: 0.7809 - val_loss: 0.6293 - val_accuracy: 0.7593\n",
            "Epoch 27/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.5867 - accuracy: 0.7786WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 340ms/step - loss: 0.5867 - accuracy: 0.7786 - val_loss: 0.6496 - val_accuracy: 0.7621\n",
            "Epoch 28/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.5896 - accuracy: 0.7709WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 341ms/step - loss: 0.5896 - accuracy: 0.7709 - val_loss: 0.6337 - val_accuracy: 0.7693\n",
            "Epoch 29/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7922WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 341ms/step - loss: 0.5620 - accuracy: 0.7922 - val_loss: 0.6272 - val_accuracy: 0.7776\n",
            "Epoch 30/30\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.7849WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "112/112 [==============================] - 38s 340ms/step - loss: 0.5710 - accuracy: 0.7849 - val_loss: 0.6301 - val_accuracy: 0.7671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJq8V-3RiYSI",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : From the above observations, one can say that the convolutional neural network training set accuracy is equal to 78.41% at the epoch of 30, which is good enough training set accuracy but can be improved by tuning the hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7GMYSrC567P",
        "colab_type": "text"
      },
      "source": [
        "## **MODEL** **EVALUATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS_o_Yp3gZb7",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : Now lets evaluate the model by checking the test and validation set accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVdkSw7NeAHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "65974550-9bd9-4bc3-c154-960afd40f956"
      },
      "source": [
        "loss_test, acc_test = model.evaluate(X_test, y_test, verbose=1)\n",
        "loss_val, acc_val = model.evaluate(X_val, y_val, verbose=1)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (acc_val, loss_val))\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (acc_test, loss_test))\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 1s 42ms/step - loss: 0.6609 - accuracy: 0.7605\n",
            "57/57 [==============================] - 2s 43ms/step - loss: 0.6301 - accuracy: 0.7671\n",
            "Validation: accuracy = 0.767055  ;  loss_v = 0.630088\n",
            "Test: accuracy = 0.760479  ;  loss = 0.660926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT0kGIgZ_AAt",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : From the above model evaluation code, one can observe that the test set accuracy is equal to 76.6467% and the validation set accuracy is equal to 77.5929% which signifies that the model is performing good enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjfEgZl6rqX8",
        "colab_type": "text"
      },
      "source": [
        "#### **TO** **PLOT** **MODEL** **PERFORMANCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDJpZjwHscJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To import matplotlib library\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kwSHtZAr3eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1. Function to plot model's validation loss and validation accuracy\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwOVjY9jnvfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "33f2572a-6e01-442b-d07d-58f9df05cc44"
      },
      "source": [
        "plot_model_history(history)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: MatplotlibDeprecationWarning: Passing the minor parameter of set_xticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: MatplotlibDeprecationWarning: Passing the minor parameter of set_xticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFNCAYAAABfWL0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hU1dbH8e9OLxBKQg8kkV4FKYKASlNUFMUCFsTer4rlXq5dr+312rvYsYCIFS+iBlFRQHqvAQKEEpIAIZCe7PePM0AIAVJmMpPk93mePMmcss+aoDlnzS7LWGsRERERERGR6svP2wGIiIiIiIiIZynxExERERERqeaU+ImIiIiIiFRzSvxERERERESqOSV+IiIiIiIi1ZwSPxERERERkWpOiZ+IhxhjYo0x1hgTUIpjrzHG/FkZcYmIiFRVureKlJ8SPxHAGJNojMk1xkQV277YdYOJ9U5kR8RSyxiz3xjzo7djERERORFfvreWJYEUqS6U+Ikctgm4/OALY0xnIMx74RzlYiAHGGKMaVyZF9aNUUREysnX760iNYYSP5HDPgGuLvJ6DDCh6AHGmDrGmAnGmBRjzGZjzEPGGD/XPn9jzPPGmFRjzEbgvBLOfd8Ys8MYs80Y86Qxxr8M8Y0B3gaWAVcVa7ufMWa2MWavMWarMeYa1/ZQY8wLrljTjTF/uradaYxJKtZGojFmsOvnx4wxU4wxnxpj9gHXGGN6GWPmuK6xwxjzujEmqMj5HY0xvxhjdhtjko0xDxhjGhtjMo0xkUWOO8X1+wssw3sXEZGqydfvrUcxxjQ1xnzvup8lGGNuLLKvlzFmgTFmn+te96Jre4jrnpnmuk/ON8Y0qkgcIu6mxE/ksLlAhDGmveumMQr4tNgxrwF1gJOAM3BuZte69t0IDAO6AT2AS4qd+xGQD7RyHXMWcENpAjPGxABnAp+5vq4utu9HV2wNgK7AEtfu54HuwGlAfeCfQGFprgkMB6YAdV3XLADGAlFAH2AQcJsrhtpAPDAdaOp6jzOstTuB34DLirQ7Gphkrc0rZRwiIlJ1+ey99TgmAUk497NLgKeNMQNd+14BXrHWRgAtgcmu7WNc76E5EAncAmRVMA4Rt1LiJ3Kkg59MDgFWA9sO7ihyw/q3tTbDWpsIvICTyICT3Lxsrd1qrd0NPFPk3EbAucDd1toD1tpdwEuu9kpjNLDMWrsK54bU0RjTzbXvCiDeWjvRWptnrU2z1i5xfVp6HXCXtXabtbbAWjvbWptTymvOsdZ+a60ttNZmWWsXWmvnWmvzXe/9HZwbNDg35Z3W2hestdmu38/frn0f4+qhdP0OL8f5PYuISM3gq/fWoxhjmgN9gX+57mdLgPc4/IFrHtDKGBNlrd1vrZ1bZHsk0Mp1v11ord1X3jhEPEHzdkSO9AnwBxBHsaEoOD1dgcDmIts2A81cPzcFthbbd1CM69wdxpiD2/yKHX88VwPvAlhrtxljfsf5dHExzqeLG0o4JwoIOca+0jgiNmNMG+BFnE9cw3D+fix07T5WDADfAW8bY+KAtkC6tXZeOWMSEZGqx1fvrSVpCuy21mYUu2YP18/XA08Aa4wxm4DHrbU/4LzH5sAkY0xdnF7NBzW6RXyJevxEirDWbsaZiH4u8HWx3ak4n+jFFNnWgsOfXO7A+aNfdN9BW3EWZomy1tZ1fUVYazueKCZjzGlAa+DfxpidxpidwKnAFa5FV7biDDcpLhXIPsa+AxSZXO/6xLVBsWNssddvAWuA1q4hLg8AB++0W3GG6BzFWpuNMxTmKpxPcNXbJyJSg/jivfU4tgP1XVMYjorHWrveWns50BD4P2CKMSbcNeLmcWttB5zpFcM4cm6jiNcp8RM52vXAQGvtgaIbrbUFOAnMU8aY2q65dfdweK7CZOBOY0y0MaYeMK7IuTuAn4EXjDERxhg/Y0xLY8wZnNgY4BegA878va5AJyAUOAdn/t1gY8xlxpgAY0ykMaartbYQ+AB40TVR3d8Y08cYEwysA0KMMee5Fll5CAg+QRy1gX3AfmNMO+DWIvt+AJoYY+42xgS7fj+nFtk/AbgGuAAlfiIiNZGv3VsPCnYtzBJijAnBSfBmA8+4tnVxxf4pgDHmKmNMA9c9dq+rjUJjzABjTGfXB6n7cJLZ0s6pF6kUSvxEirHWbrDWLjjG7n/g9JZtBP4EPsdJrsAZivkTsBRYxNGfal4NBAGrgD04C6c0OV4srpvQZcBr1tqdRb424SRQY6y1W3A+Rb0X2I2zsMvJribuA5YD8137/g/ws9am4yzM8h7OTe4AzkT247kPZz5hhuu9fnFwh2tIzBDgfGAnsB4YUGT/Xzg3wEWuT35FRKQG8aV7azH7cRZhOfg1EGcueixO7983wKPW2njX8UOBlcaY/TgLvYyy1mYBjV3X3oczj/F39EGn+BhjbfHRXCIi7meM+RX43Fr7nrdjEREREalplPiJiMcZY3riDFdtXmzCvIiIiIhUAg31FBGPMsZ8jFPj724lfSIiIiLeoR4/ERERERGRak49fiIiIiIiItWcEj8REREREZFqLsDbAbhLVFSUjY2N9XYYIiJSCRYuXJhqrW3g7TiqCt0jRURqhuPdH6tN4hcbG8uCBccqDyMiItWJMUb1IMtA90gRkZrhePdHDfUUERERERGp5pT4iYiIiIiIVHNK/ERERERERKq5ajPHryR5eXkkJSWRnZ3t7VA8LiQkhOjoaAIDA70dioiIiIiIV9SU5//yPPtX68QvKSmJ2rVrExsbizHG2+F4jLWWtLQ0kpKSiIuL83Y4IiIiIiJeUROe/8v77F+th3pmZ2cTGRlZbf/RDzLGEBkZWe0/2RAREREROZ6a8Pxf3mf/ap34AdX6H72omvI+RURERESOpyY8F5fnPVb7xM/b9u7dy5tvvlnm884991z27t3rgYhERERERMQTfPnZX4mfhx3rHz8/P/+4502bNo26det6KiwREREREXEzX372V+LnYePGjWPDhg107dqVnj170r9/fy644AI6dOgAwIUXXkj37t3p2LEj48ePP3RebGwsqampJCYm0r59e2688UY6duzIWWedRVZWlrfejojIERZu3kNGdp63wxAPW7NzH5/MSfR2GCIiPs+Xn/2V+HnYs88+S8uWLVmyZAn//e9/WbRoEa+88grr1q0D4IMPPmDhwoUsWLCAV199lbS0tKPaWL9+PbfffjsrV66kbt26fPXVV5X9NkREjrIp9QAXvzWb0e/PIyu3wNvhiAfNWpfKw9+tJD1TSb6IyPH48rN/tS7nUNTjU1eyavs+t7bZoWkEj57fsUzn9OrV64hlV1999VW++eYbALZu3cr69euJjIw84py4uDi6du0KQPfu3UlMTKxY4CIibhC/KhmApUl7uePzRbwzujsB/vo8sTqKiQwDIDHtACeHaRqCiFQNvvD870vP/rpDV7Lw8PBDP//222/Ex8czZ84cli5dSrdu3UpcljU4OPjQz/7+/iccIywiUhl+WZ1M+yYRPDG8EzPW7OKhb1dgrfV2WOIBcVHOvSsx7YCXIxERqVp86dm/xvT4lbVnzl1q165NRkZGifvS09OpV68eYWFhrFmzhrlz51ZydCIi5bP7QC4LEndzx8DWjO4dQ3J6Nq/PTKBxnRDuHtzG2+FVWcaYD4BhwC5rbacS9hvgFeBcIBO4xlq7yNNxNa8fhjGQmJrp6UuJiLiNN57/ffnZv8Ykft4SGRlJ37596dSpE6GhoTRq1OjQvqFDh/L222/Tvn172rZtS+/evb0YqYhI6c1cs4tCC0PaO3/T7j2rDTv3ZfNy/HoaRYRwea8WXo6wyvoIeB2YcIz95wCtXV+nAm+5vntUSKA/TeuEqsdPROQEfPnZX4lfJfj8889L3B4cHMyPP/5Y4r6DY3mjoqJYsWLFoe333Xef2+MTESmr+NXJNIoIplOzCMApJPvMiM6k7s/hwW+W06BWMIM7NDpBK1KctfYPY0zscQ4ZDkywzpjaucaYusaYJtbaHZ6OLSYyTImfiEgp+Oqzv+b4iYhImWTnFfD7uhQGt2+EM/LQEejvxxtXnEKnZnW4Y+IiFm3Z48Uoq61mwNYir5Nc2zwuNiqcxFQlfiIiVZUSPxERKZM5G9PIzC0osUcvPDiAD67pSaOIEK7/aD4bUvZ7IUIBMMbcZIxZYIxZkJKSUuH2YiPD2JOZp5IOIiJVlBI/EREpk/hVyYQH+XNay8gS90fVCmbCdb3wM4YxH8xj176jVyyTctsGNC/yOtq17SjW2vHW2h7W2h4NGjSo8IVjI7Wyp4hIVabET0RESs1aS/zqZE5v04DgAP9jHhcTGc6H1/Zk94FcrvlwPhnZ6iVyk++Bq42jN5BeGfP7wBnqCUr8RESqKiV+IiJSaiu27SN5Xw6D25944ZYu0XV548pTWJucwa2fLiI3v7ASIqzajDETgTlAW2NMkjHmemPMLcaYW1yHTAM2AgnAu8BtlRVbC5V0EBGp0rSqp4iIlNovq3biZ2BAu4alOn5A24Y8O6Iz909Zxj+nLOXFy7ri52dOfGINZa29/AT7LXB7JYVzhJBAf5pEhLBZPX4iIlWSevx8TK1atbwdgojIMf2yehc9YupTPzyo1Odc2qM5953Vhm+XbOf/pq/xYHTiaTGR4WxS4ici4jaV+eyvxE9EREolaU8mq3fsY0g56vPdPqAVo3vH8M4fG5m8YOuJTxCfFBsVzuY0DfUUEamKNNTTw8aNG0fz5s25/XZnZM5jjz1GQEAAM2fOZM+ePeTl5fHkk08yfPhwL0cqInJ8M1bvAihXYXZjDI9d0JG6YYGlmh8ovik2MozdB3JJz8qjTmigt8MREfE5vvzsrx4/Dxs5ciSTJ08+9Hry5MmMGTOGb775hkWLFjFz5kzuvfdenGkbIiK+K351Mi0bhBPnWt2xrPz9DPee1bZMw0TFtxxc2VPz/ERESubLz/41p8fvx3Gwc7l722zcGc559riHdOvWjV27drF9+3ZSUlKoV68ejRs3ZuzYsfzxxx/4+fmxbds2kpOTady4sXvjExFxk33ZeczdmMZ1/eK8HYp40cFafptSD9Aluq6XoxEROQEvPP/78rN/zUn8vOjSSy9lypQp7Ny5k5EjR/LZZ5+RkpLCwoULCQwMJDY2luxsFTgWEd/1+9oU8gosQzRMs0aLiQwD0Dw/EZHj8NVn/5qT+J2gZ86TRo4cyY033khqaiq///47kydPpmHDhgQGBjJz5kw2b97stdhEREojfnUykeFBdGtRz9uhiBeFBPrTpE4Iiaka6ikiVYCXnv999dnfo3P8jDFDjTFrjTEJxphxJex/yRizxPW1zhizt8i+54wxK40xq40xrxpjqmzhp44dO5KRkUGzZs1o0qQJV155JQsWLKBz585MmDCBdu3aeTtEEZFjyisoZOaaXQxs1xB/1eCr8WIjw0nUHD8RkWPy1Wd/j/X4GWP8gTeAIUASMN8Y8721dtXBY6y1Y4sc/w+gm+vn04C+QBfX7j+BM4DfPBWvpy1ffnh8cVRUFHPmzCnxuP3791dWSCJShVhrWbMzg/hVydQKCeC8zk1oGBFSKdeev2k3+7Lzy7Wap1Q/sVFh/Lwy2dthiIj4NF989vfkUM9eQIK1diOAMWYSMBxYdYzjLwcedf1sgRAgCDBAIKC7jIhUuhXb0vl+6XZCAvwIDQogLMif0CB/wlxfoYEBh38O8ic8KIDaIQEE+Fd8QIW1lqVJ6UxfsZPpK3aQWGRe1RM/rKJ3XCTnn9yUczo1pp4HV8r8ZXUyQQF+9G8d5bFrSNURGxlO2oFc9mXnERGikg4iIlWFJxO/ZkDRKr1JwKklHWiMiQHigF8BrLVzjDEzgR04id/r1trVHoxVROQo6Zl5XPvRfHYfyKXQWkq78nJwgB/tmkTQqWkEHZvWoVOzCNo0qk1IoP8Jzy0otCxI3M30lTv5acVOtqdnE+Bn6NMykptOb8mQDo1Iz8pl6tIdTF26nQe+Wc4j362gf+sozj+5KUM6NKK2Gx/GrbXEr06mX6sowoJqzrRwObYY18qem1Mz6Rxdx8vRiIhIafnKXXwUMMVaWwBgjGkFtAeiXft/Mcb0t9bOKnqSMeYm4CaAFi1aVGK4IlITPDt9NbsP5PLd7X3p2DSC7LxCMnPzycwtICuvgMzcAjJz88nKLeBAbgFZrn3b9mSxYrvTU/jZ31sACPAztGpY61Ai2KlZHdo3iaBWcAB5BYXM2ZDG9JU7+XllMqn7cwgK8OP01g2456y2DG7fkLphh3v0GtQOZuyQ2tw9uDUrt+9j6rLt/LB0B/dMXkpQgB8D2zbk/JObMrBdQ0KDTpxsHs+65P1s3Z3FrWe0qlA7Un0crOO4Ke2AEj8RkSrEk4nfNqB5kdfRrm0lGQXcXuT1RcBca+1+AGPMj0Af4IjEz1o7HhgP0KNHjxI/i7fWUoXXhSk1FYAXca+5G9OYOG8rN51+Ep2aOQ+3oa7hnJGlbMNay9bdThK4cns6K7bt4/d1u/hqURIAxjjD5nYfyCU9K4+wIH8GtG3I0E6NGdCuIbWCj/8n2hhDp2Z16NSsDuOGtmPRlr1MXbqdH5btYPrKnYQH+TOkQyNuH9CK1o1ql+v38MuqnQAMbt+wXOdL9dOivqukg1b2FBEfVROe/8vz7O/JxG8+0NoYE4eT8I0Crih+kDGmHVAPKDrjcQtwozHmGZyhnmcAL5c1gJCQENLS0oiMjKzW//jWWtLS0ggJqZyFHkSqu+y8Ah74ejnN64cydnCbcrdjjKFFZBgtIsM4t3MTwPn/dVdGDiu2pbNy+z5WbEunVkgAQzs25vQ2DUo1HPRY1+oeU4/uMfV4eFgH/t6Y5vQELtvBXxvS+O72vjStG1rmdn9ZvYuTm9ettIVkxPeFBjklHTZpZU8R8UE14fm/vM/+Hkv8rLX5xpg7gJ8Af+ADa+1KY8wTwAJr7feuQ0cBk+yRaesUYCCwHGehl+nW2qlljSE6OpqkpCRSUlIq9F6qgpCQEKKjo098oIic0BszE9iYeoAJ1/Wq8FDJ4owxNIoIoVFECIM8VAzd389wWqsoTmsVxTWnxXHxW7O54eMFfHlLH8JP0ItY1K592Szdupf7zjpG8luQD3PfgA7DoV6se4KXKiEmMkxF3EXEJ9WU5//yPPt7dI6ftXYaMK3YtkeKvX6shPMKgJsrev3AwEDi4uIq2oyI1CBrd2bw1m8buKhbM05v08Db4VRY28a1ee2Kblz/0XzumrSEd0Z3L3UtvhlrdgEcu4zDjMdg9muweipc9zP4ebQ0rPiQuKhwlXQQEZ+k5/9j011aRKq0Azn5LEjc7Za2Cgst475eRu2QAB46r71b2vQFA9o25JFhHYhfncxz09eU+rz4VclE1wulbUnzA1d+6yR9TbpC0nxY9LEbIxZfF1OkpIOIiFQNSvxEpEp74JvlXPL2HN6YmVDhtj79ezOLt+zl4WEdiKwV7IbofMeY02IZ3TuGd/7YyBfzt5zw+MzcfP5MSGVIh0ZHz5FIWQvf3Q7RPeH6nyG2P8Q/Bvur97AaOSy2SEkHERGpGpT4iUiVtXrHPr5fup0mdUL4709refHnteVe4XZHehbPTV9L/9ZRXNStmZsj9T5jDI+e34H+raN48JsVzNmQdtzjZ61PJSe/kCHF5yHmZMAXV0FACFz6MQQEw3kvQO4B+OVhD74D8SWxUc7Knola4EVEpMpQ4iciVdbzP62ldnAA0+7sz8gezXn11wSenb6mzMmftZaHv11JfmEhT13YudquAhbg78cbV55CXFQ4t3y6kE3HWY4/flUytUMC6BlX//BGa52evrQEuPRDqONKkBu0hb53wdKJsOkPD78L8QUx9Z0ev0SVdBARqTKU+IlIlbQgcTcz1uzi5jNaUi88iGdGdHaGMv6+kcenripT8vfjip3Er07mniFtaBEZ5sGovS8iJJD3x/TE389w3Ufz2ZuZe9QxBYWWX9fsYkDbhgT6F7lNzHkdVn0Hgx+DuNOPPOn0+5yVPX+4B/JzPPkWxAeEBvnTOCKERK3sKSJSZSjxE5Eqx1rLcz+tJapWMNf2jQXAz8/wxPCOXN8vjo9mJ/LgtysoLDxx8peemcej36+kY9MIrutbM1YBaxEZxjuju7NtTxa3frqI3PzCI/Yv3rKHtAO5R67muWkW/PIotD8fTrvz6EYDQ+HcFyBtPcx+1cPvQHxBTGSYhnqKiFQhSvxEpMr5fV0K8zbt5s5BrQgLOlyVxhjDQ+e157YzW/L531u4f8oyCk6Q/D07fTVp+3N4dkQXAvxrzp/EnrH1efbizszZmMbD3644oof0l9XJBPgZzmzrKmexbztMuRbqnwTD34RjDYVtPRg6XAh/PA+7N1bCuxBviosKZ7MSPxGRKqPmPOWISLVQWGj5709raV4/lFE9Wxy13xjD/We3ZezgNny1KIm7v1hCXkFhCS3B3I1pTJy3lev7xdE5uo6nQ/c5I06J5o4BrfhiwVbem7Xp0Pb4Vcn0PimSiJBAyM+FL6+B3EwY+SmERBy/0aHPgF8gTLvfmRMo1VZMZDip+3PJUEkHEZEqQYmfiHicOx8Mp63Ywcrt+xg7uA1BASX/CTPGcNfg1vxraDumLt3OPz5ffNRwxuy8Ah74ZjnR9UIZO6SN2+Krau4Z0oZzOzfm6R9X88uqZDam7GdDygEGt2/oHPDzQ7D1bxj+OjRsd+IGI5rCwAchId6ZDyjVVpxrZc/NmucnIlIlKPETEY+x1vLU/1bR9YlfmL5iZ4Xbyyso5IWf19GmUS2Gdz1xyYVbz2zJI8M6MH3lTm75dCHZeQWH9r05M4GNKQd4+qLORwwXrXTJK526eF7i52d44dKudG5Wh7smLeaNmRsAGNS+ESybDPPegT53QKcRpW+0543QuAtMHwfZ+zwUuXhbjKuW3/FWhxUREd+hxE9EPMJay39+WM27szYRERLA2C+WsHJ7eoXanLIwiU2pB7jvrLb4+5Wu5MJ1/eJ48sJO/LpmFzdOWEBWbgHrkjN46/cNXNStGae3aVChmCokNxMmXAifXgx52V4LIzTIn/eu7kGd0EC+WpREu8a1aZ67Eb6/E2L6Oqt4loV/AAx7GTJ2wsynPRGy+ICYyIM9fkr8RESqAiV+IuJ21loen7qKD/7axLV9Y/np7tOpGxbIjR8vICWjfEv9Z+cV8Er8erq1qMuQDo1OfEIRV/WO4blLuvBnQirXfjSPf321jFrBATx0XvtyxeI289+DA7sgfSsseN+roTSMCOG9MT2oHRLAqM4RMHk0hNSBSz4E/8CyNxjdHXpe7/QYbl/i/oDF68KCAmgUEcymVA31FBGpCpT4iYhbWWt59PuVfDQ7kev7xfHIsA40jAjh3at7sCczj5s/WUBOfsGJGyrmkzmb2bkvm3+e3a5cBdYv69Gcl0d2ZX7iHhZv2ctD53UgslZwmdtxm5wM+OtlaDkQTjrTWQnTy8MiOzatw/wHBjIm+RnYuwUu+xhqly3JPsLAhyEsCn4YC4Vl/zcX3xcbqZU9RUSqCiV+IuI2hYWWh79bwYQ5m7np9JN46Lz2h5K0Ts3q8MJlJ7Noy17+/fXyMhVYz8jO483fEujfOoo+LSPLHd/wrs149+ru3D24NSNOOfEcQY+aNx4y02DAgzDoUcja7RRI97KQua9g1k2Hs5+GFr0r1lhoXWeVz+2LYMEH7glQfEpsZLhq+YmIVBFK/ETELQoLLQ99t4JP527h5jNO4t/nHN0zd27nJowd3IavF21j/B+lr/P27qxN7MnM459nl2JVyRMY2K4Rdw9uU65eQ7fJ3gd/vQqtz4boHtDsFKf+3ezXYf8u78W14mv49UnofCn0usk9bXa6GOLOgBlPQEaye9oUnxEbpZIOIiJVhRI/EamwwkLLg98u5/O/t3DbmS0ZN/TYwzHvHNSKYV2a8Oz0NcxYfeJEIG1/Du/P2si5nRtXn1p7c9+C7L0w4N+Htw18GPKznSGf3rDxd/jmZmjRBy547dhF2svKGDjvRee9/fyge9oUnxEbqZIOIiJVhRI/keooeRUU5FfKpQoLLf/+ejkT523ljgGtuP/stsftTTPG8N9LTqZT0zrcOXExa3dmHLf9N2ZuICuvgHuGtHV36N6RtQfmvAHthkHTboe3R7WCU0Y7QyL3JFZuTDuWwaQroX5LuPxzCAx1b/tRraDfPbD8S9gw071ti1fFRjklHTTcU0TE9ynxE6lu0jbAW6fBd7dBGebRlUdBoeWfXy3jiwVbuXNQa+49q3RDKEOD/Hn36h6EBwdw/cfzSdtf8kqf2/Zm8enczVzSPZpWDWu5J+i8bEhPck9b5THnTchJhzP/ffS+M/4Ffv4w85nKi2dPInx2ibOC51VfQWg9z1yn31iofxL8716vlq4Q94pRj5+ISJWhxE+kukmIByws+wJmveCxyxQUWu6fspQpC5O4e3Br7hlStnlzjeuEMP7qHqRk5HDrZ4vIzS886phX4tcBcNfgNu4JOvcAfHQuvNbd6RWtbJm7nWGeHS6Exp2O3h/RFE692fm327nC8/EcSIVPRkB+Doz+Gup4cMGbwBA47wXYvQEWTfDcdaRSHS7poB4/ERFfp8RPpLpJiHd6VjpfBr/+B1Z9f8xDc/IL+Hh2IkNf/oNL3prN2C+W8OLPa5m8YCtzNqSRtCeTgsKjew0LCi33fbmUrxdt454hbbi7nIlZ1+Z1ee6SLszbtJtHvltxxEqfCbv2M2VhElf1jqFZXTcMPSzIg8ljYPtiCAiBKdc6BdQr0+xXIXc/nDnu2Mf0GwshEc6/nSfl7IfPLoV92+CKydCgEobSthzoXKvHdZ6/llSaGJV0EBGpEgK8HYCIuFFeNiT+Cd2ugiH/gT2bnAU76raApl0PH1ZQyFcLk3h1xnq2p2fTtXldAvwN8zbt5rslWRTN9QL8DE3rhtK8fijN64XRvH4YK7al8+OKndx3VhvuGNi6QiEP79qM9cn7eX1mAm0a1ea6fnEAvPjLWkID/bl9QMsKtQ84Q16/vxMSfoFhL0G9WPjkIpg+Di54teLtl8b+FPh7vLPKZcPjFKEi8DEAACAASURBVI4PrQd974YZj8PmORDTx/2xFOTB5KthxxIY+Rm0ONX91ziWNmdX3rWkUsRFhjNjjRdXoxURkVJR4idSnWyZA3mZ0HKQM7Ru1OcwfgBMvBxu/JWCWo2ZunQ7L8evIzEtk5Ob1+W5S06mb6vIQ8M08woK2b43i627s9i6J5OtuzPZuieLrbsziV+dTOr+XADuP7sttw9o5Zaw7xnShnXJGTz5v1W0bFiL+mFBTFu+kzsHtXZPkfUZj8PSz+GMcYd7m/re7SqgPgA6XlTxa5zIXy9Dftbxe/sOOvUW+PsdiH8MrpvuvhU2AQoL4bs7YMMMOP9VaHeu+9qWGikmKozU/Tnsz8mnVrAeK0REfJX+QotUJxtmgH8QxPZzXtdqCFdMwr5/NukfXsJV+Y+yIiWP9k0ieO/qHgxq3/CoeXmB/n7ERIYTExle4iUyc/M5kFNAg9puSMhc/PwML43sysVvzeaOzxdxUlQ49cICubF/XMUbn/s2/PkSdL/myKRr4ENO7+j3dzmra9aLrfi1jiVjJ8x/D7qMhKhS9JAGhcGZ/4IfxsK6n6DtUPfFMuMxWDYJBjwE3ce4r12pseJcfysSUw/QqVk1KbkiIlINaY6fSHWS8Cu06A3BzgqY1lpm7m3Ef4LvIWL3Su7NepnXL+/K//7Rj8EdGpWriHlYUIBbk76DwoMDeG9MD4ID/FialM7tA1pROySwYo2u+MoZztlumFNLruj79Q+ES94HLEy53hn+6Cl/vuS0f8Y/S39Ot9HOXM0Zj0NhgXvimPMm/PUK9LwBTr/PPW1KjXfwQyKt7Cki4tuU+IlUF/u2w66V0GowALMTUrn4rdlc+9F8fik8hZUdxjIg/y+G7fkEPz83Dh10o+h6Ybw/pidX94nhqt4xFWts4+/wzS1OQfKL33PKJBRXL9aZ47dtAcx8qmLXO5b0bbDgQ+h6hZPIlZZ/oNMruWuVU/+uopZPgZ/+De0vgHOec+/wUanRDpZ0UC0/ERHfpqGeItXFhl8BWB7Sg2fencvsDWk0jgjhqYs6cVmP5gT6DYDvkuG3Z5zhhp0u9nLAJTu5eV1Obl63Yo3sWFr6guQdL3KKiv/5EsSd7qw86U5/vgi2EE6/v+zndrgImrziJKUdL4KAcva0bpjpJMExfWHEuyUnwSLlFB4cQMPawSSqpIOIiE9Tj59INZG6ZBq7/epz/pd7WJecwcPDOvDb/Wdy5akxBPr7OT08w15yesC+vQ2SFno75GPLyyr/uXsS4dMyFiQf+iw0aAdf3wz73bg64d4tsPBjOGU01CtHD6afHwx61NXOR+WLYfsS+OIqiGrjLPYTGFK+dkSOIzYyXD1+IiI+TomfSBVmrWV2Qioj3/6TgMTf+MuezMPDOjLrnwO5vl8cIYHFenYCgmHkp86iL5Mud4Yh+pr578NTTeCjYc7PB1JLf+7BguQFuWUrSB4UBpd8ADn7nJ6xwqOLyZfLH887CXf/e8vfRsuBENsffn8OcjJKf17yKph6F3ww1El+r5oCoRXsSRU5htioMBI1x09ExKd5NPEzxgw1xqw1xiQYY45aw9wY85IxZonra50xZm+RfS2MMT8bY1YbY1YZY2I9GatIVWKtZdb6FC57Zw5XvPc34anLqGsOcPbwK7i+XxyhQccZyhce5RTRzs2EiaMg14c+pc/a4xQub9AW9ifD/+6B59s4NfcWfeLsP5ZDBcm3l68geaOOcPbTzsqoc16r2PsA2L0JlnwG3a+FOtHlb8cYGPw4ZKY6i7McT0E+rJ7qJM1v9YGlk6DzJXDN/yCiafljEDmBmMhwUjKckg4iIuKbPDbHzxjjD7wBDAGSgPnGmO+ttasOHmOtHVvk+H8A3Yo0MQF4ylr7izGmFuCmj+BFqi5rLX+sT+WV+HUs2rKXxhEhPDG8I5dnLoVZhqA2g0vXUMP2cOmH8PllToH3Syc4wwq97Y/nIWsvjJkKjTpB8gpY8TWs/Bq+v8Mpb9BqEHQc4dSfC67tnHeoIPlSGFWBguQ9roONv8GMJyCmH0R3r8B7+S/4BUD/e8rfxkHR3aH9+TD7Neh5vZO8F5W5GxZ97PSQpm+FOs1h8GNwyhgIq1/x64ucQFzUwZU9D9CxqUo6iIj4Ik8u7tILSLDWbgQwxkwChgOrjnH85cCjrmM7AAHW2l8ArLX7PRiniM+z1vLbuhReiV/Pkq17aVonhP9c2InLekQTHOAP782EZqeU7SG/9RA46ylnpceZT8KgRzz3Bkpj9yaYNx66XgmNOzvbGnd2vgY9AtsXuZLAb2HddAgIcd5DxxFOrbsNM+CC16DtOeWPwRhnlc+3F8OUa+GWWc5cwbJK2wBLJ0Lv26B24/LHU9TAh2HN/2DWizD0aWfbzuVOofflX0J+tjMkdOgz0OYc8NfaXVWVMWYo8ArgD7xnrX222P4Y4AOgAbAbuMpam1TpgRZxaGXP1EwlfiIiPsqTTwbNgK1FXicBJX4M77qJxQG/uja1AfYaY752bY8HxllrC4qddxNwE0CLFi3cGryIt1hrSdmfw7qd+1mbnMG6nRks2bqXtckZNKsbylMXdeKS7q6ED5zhj9sWQP9y1GXrfSukrIFZL8C6n51VLeP6Q8xp5Ut4KmLG404P2cCHjt5nDDTr7nwN+Q8kzXOSwFXfOkMbwSlIfsrVFY8jtB5c/D58eI7Tw3jx+2UvffDbs05i2veuisdzUIO2TlI8/11o0AaWTYbNf0FAKJw8Cnrd5AxXlSqtNKNlgOeBCdbaj40xA4FngNGVH+1hsQeLuGuBFxERn+UrHwmPAqYUSewCgP44Qz+3AF8A1wDvFz3JWjseGA/Qo0cPW1nBirhLelYe65MzDiV4a3ZmsC45gz2Zh4uJR4YH0bZxbZ7p25mLT4kmKKDYkMyNvznlAlqVcphnUcbAuc9DZEtIiIcF78PcN8D4QZOurkTwdKcofFB4xd7s8WydByu/gTPGQUST4x/r5+fE06K307u1+S/ISHbmsrlLi1NhwAPOfMOTBjircpZWylqnB67vnc4iOu505jgn4Zt6F9RtAWc9Cd2uKt3KpVJVlGa0TAfg4BjimcC3lRphCcKDA2igkg4iIj7Nk4nfNqB5kdfRrm0lGQXcXuR1ErCkyI3vW6A3xRI/kapof04+j3y3gjkb0tiRnn1oe63gANo0qsXQTo1p06g2bRvVpk3j2kTVOkHttoR4CK7j9IaVR0CQ0zPV9y7Iy4ak+bDpD0icBXNeh79eBr9AiO7hDCWMOx2ie7qvLIC18NMDUKuxkyyVhZ+/E48n9BsLm36Hafe7htFGwYEUZ5GVA6nOz4e+imzbn+wkyae5sbfvoDrRcMUkyM91hrmqHl91VJrRMkuBETjDQS8CahtjIq21aZUTYsniIsPZrJU9RUR8licTv/lAa2NMHE7CNwq4ovhBxph2QD1gTrFz6xpjGlhrU4CBwAIPxipSKfYcyOWaD+exYvs+hnVpQvsmEYcSvKZ1QjBlHVJoLST8Ci3PdM+crsAQZ6hnXH/nde4B2DL3cCI463n44zkIquXUhDvpjIpfc+U3TrJ5wWue7VUsKz9/uGg8vN0P3jqt5GOMv7PQSngD53u9Hs7P7c6D8EjPxOXuAvNSFd0HvG6MuQb4A+ceW1D8ILdOh1g91aklecWXx1wIKiYyjN/WpVTsOiIi4jEeS/ystfnGmDuAn3AmqH9grV1pjHkCWGCt/d516ChgkrXWFjm3wBhzHzDDOE/CC4F3PRWrSGXYkZ7F6PfnsWV3Ju9c1Z3BHRpVvNGUNZCxHVoOqnhbJQkKd1bRbOVqPzsdNs+B+EedVTRvmAFRrcrffn4OxD/mrODZ9Uq3hOxWEU3g6u+cRVXC6rsSvAaHE72Qur6xGqpUJyccLWOt3Y7T44dr1euLrbV7Kcat0yHyc5zRBQnx0OasEg+JjQonZWESB3LyCQ/2lZkkIiJykEf/MltrpwHTim17pNjrx45x7i9AF48FJ1KJNqbsZ/T780jPymPCdb3ofZKbeoMS4p3vrTyU+BUXUgfaDoWG7eDdgTBxJNwQX/45ZvPGw97NMPob3x222LiT8yVSOU44WsYYEwXsttYWAv/GWeHTs9pf4AzHnvfOsRO/Igu8aGVPERHfo4+qRTxsxbZ0Ln17Dtl5BUy6qbf7kj6AhBnQoF3FCoSXR71YGPkZ7NkMk8c4dfTKKnO3U+uu1RANXxRxsdbmAwdHy6wGJh8cLWOMucB12JnAWmPMOqAR8JTHAwsIgh7XOh82pW0o8ZDYKKekg+b5iYj4JiV+Ih7098Y0Lh8/l5BAf768pQ+dmrnxU/DcTNg823PDPE8kpg+c/4qzAMqP/3TmG5bF7/8HORlw1n88E59IFWWtnWatbWOtbWmtfcq17ZGDUySstVOsta1dx9xgrc2plMC6X+ss9DSv5JkXMSrpICLi05T4iXhI/Kpkrv5gHg0jgvnylj6c1KCWey+w+S8oyKm8YZ4l6Xalsxrogg+O+TBYotQEmP8enDIGGrb3XHwi4j61G0GH4bDkM8jZf9TuWirpICLi05T4iXjAN4uTuPnThbRtXJsvbzmNpnVDD+/MToeJlzv12CoiYYZTJDzmGCtOVpZBj0Lbc2H6v5yYSiP+USf2AQ94NjYRca9Tb4acfbBsUom7YyPDSNRQTxERn6TET8TNPvxrE2O/WMqpcfX5/Mbe1A8POrwzLxsmXgFrp8EP98C+7eW/UEI8xPaDwNATH+tJfv4w4l1o2AG+vNYpYH48iX/Bmh+g393uL3AuIp4V3ROanOz08JcwvDs2Mlw9fiIiPkqJn4ibWGt56Zd1PD51FWd1aMQH1/SkVtElzQsL4OsbYfOfMOgRKMyD6f8u38X2bIa09d6b31dccC24fJKzAMTnI52FW0pSWAg/PwgRzaD37ZUbo4hUnDHQ62anlMymP47aHRsVzq6MHDJz870QnIiIHI8SPxE3KCy0PPb9Sl6ZsZ5Lu0fz5pWnEBJYpDyBtfDjv2D193D209D/Xuh/H6z6FtbHl/2CG1xDKr05v6+4us2dou77tsMXoyE/9+hjVkyB7YudxDcorPJjFJGK6zQCQus75ViKiYl0/r9OTNVwTxERX6PET6SCrLXcP2UZH8/ZzI3943juki4E+Bf7X2vW8zD/XTjtH9DH1dPV906IbA3T7oW8rLJdNGEG1GkOUW3c8ybcpXkvGP6606v5v3uOHAqWlwXxjzvDxDpf5r0YRaRiAkOh+xhnyPrerUfsOljLb7NW9hQR8TlK/EQqaPwfG/lqURJ3DmrNA+e2xxhz5AGLJsCvT0KXkTD4icPbA4Jh2IuwJxFmvVD6CxbkOUOsWg50hl35mi6XOb2Ziz+BuW8e3j73TdiXBGc9BX760yNSpfW4zvm+4P0jNsdGOYnfJiV+IiI+R09fIhUwOyGV/5u+hnM7N2bs4NZHJ31rf4Spdzlz8Ya/cXTCE3c6dBkFf74MKetKd9Gk+c6qeq0Gu+dNeMKAB6H9+fDzQ7DuJ9ifArNeclb/jOvv7ehEpKLqtnD+f174sbNolUut4ACiagWzWUM9RUR8jhI/kXLavjeLOyYu5qQGtXjukpOPTvq2/A1fXuMMbbxsAvgHltzQWU86892KD408loQZYPzhpDMq/B48xs8PLnoHGneGKdfD93dAfhYMeeLE54pI1dDrJsjaDSu+OmJzbGSYevxERHyQEj+RcsjOK+DWTxeSm1/IO6O7H7l6JzglDSaOhIimcMWXzqqXx1KrAQx+DBJnwbIvTnzxhHhnSfWQOhV5C54XFA6jJjrf1013hoZFtfZ2VCLiLnGnQ4N2MO+dIz60io0K1xw/EREfpMRPpBwen7qSpUnpvHDZybRsUCypS98Gn4wAv0C46msnsTuRU65xkrmfHjx2KQSAA6mwY6lvD/Msqk4zuOIL6HwpnDHO29GIiDsZA71udP4mJc0/tDk2MozkfSrpICLia5T4iZTRpHlbmDhvK7cPaMnZHRsfuTNrD3x6MWSnw1VToH5c6Rr184NhLznnzzjOcMgNMwELrQaWO/5K17QrXPwehEd6OxIRcbcuoyA44ojSDgcXeNmcpnl+IiK+RImfSBks2bqXR75bSf/WUdwzpO2RO/OyYOIVkJYAoz5z5vaVRePO0PtWWPghbJ1X8jEJ8RAWCU26le8NiIi4U3At6HolrPwWMpKBwyUdElM13FNExJco8RMppbT9Odz26UIa1A7m1VHd8PcrsphLYQF8dQNsmQMj3in/witnjoPaTeGHsVBQbJhUYSFs+BVOGqByCCLiO3reAIV5sPAjoEgRd/X4iYj4FD09ipRCfkEh/5i4mLQDubwzujv1woOcuXibZ8P892DSFbDmBxj6LHS6uPwXCq4N5/wfJK+Av98+cl/ycjiwC1oNqtibERFxp6hWzrzjBR9Afi61QwKJqhWkHj8RER8TcOJDRHyXtZbcgkKycgvIdH05P+eTmVdAZo7zc1TSz7Q+sJimzZrjV6sBhDeAsCjne3iUs0LmsYqh52Tw2XfTiU78m8fa5tBmxjuwazXs33n4mOAIGPAQ9L6l4m+q/fnQ+myY+TR0vBDqRDvbE2Y431tWofl9IlIz9LoJPr8M1kyFThcTGxlOolb2FBHxKUr8pMopLLQ8+v1Kvl28jcy8AgoKj1/7LpRs5gQ/TBjZ+K0vKPkgv8DDSeDB71l7IWU17N3CGIBAYEsoNGjrJF8N20PDDtCwHUQ0O3biWFbGwLnPwRu94cd/OfMFwRnm2agz1G58/PNFRCpbqyFQLxbmvQudLiYmMpxZ61O8HZWIiBShxE98w/YlTu27k0ce9zBrLU/8sIpP5m5mWJcmxESGERYUQGigP2FB/oQG+RMWFFDkZ38arv2cujMPMOeMz3hzfR3WbUyksf8+hsQGMDQugJZhmZgDqU6phAMpzlfqegiuRUZUNz7Y3YfMem2498qLCIqKBT9/z/8+6sXCGfc7K3yunQ6xfZ35g33u8Py1RUTKys8Pet4IPz8IO5bRrUVdvlqUxPKkdDpH+3jNURGRGkKJn/iGX//jDGWM7gGRLY952Csz1vPR7ESu7xfHQ+e1x5yol81amPIBNDmZPmeeR58Bhg0p3fhs7hbGL9zK8xvyadWwFlee2oIR/aKpExp46NR92Xlc+Ppf7AvK44fr+hNUJ8Rd77Z0+vwDln4B0+6HwY9CYb7m94mI7+p2Jcx8CuaN54KzX+LJ/61i4vwtdI7u7O3IREQELe4iviAvCxL/BCz89coxD/vor028HL+eS7pH8+C5pUj6wBkemboWTr310FDMlg1q8cj5HZj34GD+e0kXwoMDeHzqKk59Op5/TlnKsqS9FBZa7pu8lM27M3njilNoXNlJH0BAkFPbL30L/HAPBIZD896VH4eISGmE1oMul8HyL4kozOC8zk35bvE2DuSokLuIiC9Q4ifet3k25GdDg3awdCLs23HUId8sTuKxqas4q0Mjnh3RGT+/Us6n+/ttCG8InUYctSsk0J9LezTnu9v78sM/+nFRt2ZMXbqDC17/izOen8nPq5J54Nz2nHqSFwuPx/Z1amTlpEPc6U4yKCLiq3rd5Pw9X/wJV5zanAO5BfywbLu3oxIREZT4iS9ImAH+wXDpR85wxrlvHrE7flUy9325jNNaRvLq5d0I8C/lf7apCbD+Z+hxHQQEH/fQTs3q8MyILvz94CCeGN6R2sGBXN6rOdf1jS3fe3KnIU9AVBvnk3QREV/WqCPE9IP573FKdAStG9Zi4ryt3o5KRERQ4ie+YMMMiDnNWSWz4winFlTWHgDmbkzjts8X0alpBOOv7kFIYBkWVpn3jrNaZ4/rSn1KREggV/eJZdpd/XlmRJfSDSf1tPAouGN+ib2WIiI+p9eNsHcLZv3PXN6rBUu27mX1jn3ejkpEpMZT4ifelZ4EKWsOL1rS727I3Q/z32fFtnRu+HgBLeqH8dG1vagVXIa1iLLTYcnnTjH12o08E7uIiByt3TCnxM28dxhxSjOCAvyYNG+Lt6MSEanxlPiJdx0qSu5K/Bp3hlZDyJ/zJje+P4s6oYF8cn0v6oWXcW7b4k+dBNIdBdVFRKT0/AOcXr+Nv1F313zO7dSYrxdvIyv3GHVURUSkUng08TPGDDXGrDXGJBhjxpWw/yVjzBLX1zpjzN5i+yOMMUnGmNc9Gad40YYZULupM8zTJaXrbQRkpTGcmXx6w6k0qRNatjYLC+Dvd5wVMJt2c3PAIiJyQr1udv62//wgo3pGk5Gdz7TlRy/cJSIilcdjiZ8xxh94AzgH6ABcbozpUPQYa+1Ya21Xa21X4DXg62LN/Af4w1MxipcV5MOG36DVwEOlFtL25zByumEJbbgn/Cfi6h1/UZYSrZsOezdD71vdG6+IiJROUBgMehi2L+bU/b9yUlQ4EzXcU0TEqzzZ49cLSLDWbrTW5gKTgOHHOf5yYOLBF8aY7kAj4GcPxijetG2hU6ag1WAAMrLzGPPhPLanZxM+8D6CMrbCym/K3u7ct6BOc2eeiYiIeEeXUdC4C2bGE1zZvQELNu9hfXKGt6MSEamxPJn4NQOKruGc5Np2FGNMDBAH/Op67Qe8ANznwfjE2xLiwfjBSWeSnVfADR8vYM2ODN66sjut+13q1PX78yWwtvRt7lwBibOg5w3OPBMREfEOPz84+ynYl8SowmkE+hsmzVdpBxERb/GVxV1GAVOstQdnft8GTLPWJh3vJGPMTcaYBcaYBSkpKR4PUtxswwxo1oOcwAhu/XQh8xJ388JlJzOgXUPngaHv3bBrJaz/pfRt/v02BITCKVd7Lm4RESmduNOhzTmE//0KI9oG89WiJLLztMiLiIg3eDLx2wY0L/I62rWtJKMoMswT6APcYYxJBJ4HrjbGPFv8JGvteGttD2ttjwYNGrgnaqkcmbth2yLyTxrI7Z8tYubaFJ6+qDPDuxbpFO58CUREO71+pXEgFZZNhpNHQVh9z8QtIiJlM+QJyMvkbv+v2JuZx08rd3o7IhGRGsmTid98oLUxJs4YE4ST3H1f/CBjTDugHjDn4DZr7ZXW2hbW2lic4Z4TrLVHrQoqVdiGXwHLcwnRxK/exZMXduLyXi2OPMY/EE77B2yZDVvmnrjNhR9CQQ6cqhIOIiI+o0Eb6HEdjRMm0a9uqhZ5ERHxEo8lftbafOAO4CdgNTDZWrvSGPOEMeaCIoeOAiZZW5aJXFLVFSbMYL9fbd7bWJcnhnfkqt4xJR94ymgIrQ9/vnz8BgvyYP77cNIAaNjO/QGLiEj5nTkOExTOk2GTmbtxNxtT9ns7IhGRGsejc/ystdOstW2stS2ttU+5tj1irf2+yDGPHa83z1r7kbX2Dk/GKZUrP7+AfSt+4re8jjxyfieu7hN77IODwp0evHU/QvKqYx+36jvI2KESDiIivig8CvrfS+zuP+nvv5IvtMiLiEil85XFXaSGyC8o5LlPvqZuQRq1Ow3lmr5xJz6p140QGA5/vXLsY+a+BfVbQqsh7gtWRETc59RboE4Lng6fxNcLNpObX+jtiEREahQlflJpCgot9365FJMwA4AzzhlZuhPD6kP3a2D5l7C3hLkhSQtg2wI49WZnNVAREfE9gSEw+FGa527gzJwZxK9O9nZEIiI1ygmfko0x57vq6omUW0Gh5b4vl/Ldku2MbpAADTtCRNPSN9Dndqfm3+zXj9439y0IjoCuV7gvYBERcb9OF2Ob9eBfgV/y9dy13o5GRKRGKU1CNxJYb4x5zrUCp0iZFBRa/jllGd8s3sYDg5sTnbEUWg0sWyN1mkGXy2DRBKdsw0H7tsOqb6HbVRBc272Bi4iIexmDOftpothDx8QJbN2d6e2IRERqjBMmftbaq4BuwAbgI2PMHFfhdD1lywkVFlrGfbWMrxYlcc+QNtzUfDsU5EKrwWVvrO9dkJ8Ff79zeNv896GwAHrd5L6gRUTEc1qcSlbrYdwc8ANT/1ro7WhERGqMUg3htNbuA6YAk4AmwEXAImPMPzwYm/iSwsIje9pKdYrlgW+W8+XCJO4a1Jo7B7WGDTMgMAxa9Cl7DA3aQrthMG885OyHvGyndl/bc6B+KRaJERERnxB6zn8IMgVEL3qRvAIt8iIiUhlKM8fvAmPMN8BvQCDQy1p7DnAycK9nwxOfMfsVeLEDpKwr1eGFhZaHvlvBpPlb+cfAVtw9uLWzIyEeYvtBQHD54uh7N2TvhUUfO4u9ZKaphIOISFVT/yS2tRnNsMKZzJ/7h7ejERGpEUrT43cx8JK1trO19r/W2l0A1tpM4HqPRie+IT/XWUClIAemjwNrj3notr1ZjP9jA+e//ief/72F285syT1D2mCMgd2bYPfG8g3zPKh5T4jt7yzyMvdNaNTJeS0iIlVKswseIcOEU2fW48e9r4iIiHuUJvF7DJh38IUxJtQYEwtgrZ3hkajEt6z6FvYnQ5uhzlDNddOP2J2SkcPHsxO55K3Z9H32V56etoYAfz+eGdGZ+89u6yR94JwL0HJQxeLpdzdkbIddq5wSDgfbFxGRKiOgVn0Wxt5Ex+xFpC75wdvhiIhUewGlOOZL4LQirwtc23p6JCLxLdY6vX2RreGyCfB2f5g+jr1N+vLT2r1MXbqD2RtSKbTQrnFt7j+7Led3aUqLyLCj20qYAXVjILJlxWJqOQgad4F926DzpRVrS0REvKb1eXex6bXPiPj5YehyDvw/e/cdVdWxPXD8O3TpiCBgQ1Cs2LuxoMbYY0xiNNF089L7e4npyS++VF+K6TGJ0cSYRFOMvSb23rCggqKCHRSlt/n9MaColAvcC4L7s9Zdl3vunDlz0MVlMzN721vya4kQQoiysOQnrIPWOjP/hdY6UynlZMMxiatJ3EY4ugUGvU9yjj3bG/+b7mvvZ/J7z/JJ1o0E+7rySEQjhrYOIqx2n16JrAAAIABJREFUMYleszPh4ApTkqG8M3RKwagfTYIXxxrl60sIIUSlqefnzUf+D/LE6dfJ3TIVu473VvaQhBCi2rIk8DullBqmtZ4NoJS6EShdekdRda37DJy9+F33ZPybi0nPcuV71048bjebwWOeoWlY2MWlnMU5sh4yk8u3v68g7/rW6UcIIUSlCus5ivUzf6b1srdxaX832FmUcFwIIUQpWfLT9UHgBaXUYaXUEeA54F+2HZa4KiTFwe7ZHGl4C8/+GUObet78+mBXejzyFU4ql2Y737cs6AOzv8/OQRKxCCFECZRSA5RSe5VS0Uqp5wt5v75SarlSaqtSaodSalBljNNa+rUIYLbDAFzSTkD8psoejhBCVFuWFHCP0Vp3AZoDzbTW3bTW0bYfmqh0Gyej0dy7uw1Nansw+a6OdAyuiZ1vQ+j+OET+AofXWdZX9BKo1xlcPG07ZiGEqMKUUvbAp8BAzOfuaKVU88uavQT8orVuC4wCPqvYUVqXo70dQR1vJFPbE7fm58oejhBCVFsWradQSg0GHgaeVkq9opR6xbbDEpUuM5WcTVP4m46k1KjDd/d0xN25wMrg654Czzow79+Qm1N8X8kn4XgkNCpnNk8hhKhClFJuSim7vK/D8uriOpZwWicgWmt9IG9//QzgxsvaaCD/r2hewFFrjrsy3NevNVsdWkPUHFLSsyp7OEIIUS1ZUsD9C+A24DFAAbcCDWw8LlHJUjf/hH36GabqgUy5txO1PV0ubeDkBv3/D47vgC1Ti+8sZpl5Lm8ZByGEqFpWAC5KqTrAImAsMKWEc+oARwq8jss7VtBrwBilVBwwD/P5XKW5ONpTu9PN1NXHmfrHvMoejhBCVEuWzPh101rfCZzRWr8OdAXCbDssUZkysrJJWPoRe3QDxo0ZU3S2zhYjoEF3WPoGpJ0pusPoJeDmZ0owCCHEtUNprVOBEcBnWutbgRZW6Hc0MEVrXRcYBEzLn1m85OJKPaCU2qSU2nTq1CkrXNa2gruPRKNI3/knm2ITK3s4QghR7VgS+KXnPacqpYKALCDQdkMSlUlrzeSpU6iXfYi0tuPo1siv6MZKwcB3IP0sLH+r8Da5uWbGL7SPZGoTQlxrlFKqK3AHMDfvmH0J58QD9Qq8rpt3rKD7gF8AtNZrAReg1uUdaa2/0lp30Fp38PMr5mf51cLdn9y6nRniuJn/zNxBelYJ2wiEEEKUiiW/if+llPIG3gO2ALHAdFsOSlSe9xftJSz2R1IdfWg3eFzJJwSEQ4d7YeNkOLHryvePbYPUBOuVcRBCiKrjSWA88LvWepdSKgRYXsI5G4HGSqmGeTVzRwGzL2tzGOgLoJRqhgn8rv4pPQvYtxhGYx1LVsIBPlyyv7KHI4QQ1UqxgV/e0pGlWuuzWutZmL19TbXWktylGpq+/jB//b2GvvZbqdH1fnB0KfkkgIgXTbbO+c+B1pe+F7PUPIdEWHewQghxldNa/6O1Hqa1fifv8/S01vrxEs7JBh4FFgJ7MNk7dyml3lBKDctr9gwwTim1HfgJuFvry3/4VlFNhwDwXINovl55gB1xZyt5QEIIUX0UG/hprXMxaaXzX2dorZNsPipRapnZuSzYeYxT5zPKdP7yqJO8/OdOXqq1AmXngOp4v+Unu9aEPi9B7ErY/eel70Uvg8DW4F4FlhkJIYQVKaWmK6U8lVJuwE5gt1Lq3yWdp7Wep7UO01qHaq0n5B17RWs9O+/r3Vrr7lrr1lrrNlrrRba9kwrk0wACWjHAfiO13J34z8wdZGbnVvaohBCiWrBkqedSpdTNyuJK3aIyfLBkHw/+sIXO/13CmMnr+XnjYZJSLUuJHRmXxCPTt9Cutj3XZyxGtbgJPAJKN4D290DtcFj0EmSmmmPpSXBkvSzzFEJcq5prrc8Bw4H5QENMZk9RnGZDcYjfyLs31Cbq+Hk+/zumskckhBDVgiWB37+AX4EMpdQ5pdR5pdQ5G49LlELU8XN8veIAg8IDeCSiEUfOpPLcrEg6TFjMfVM28ue2eFIysgs990hiKvd+vxEfVye+bb0PlZkMXR4s/SDs7E2il6QjsPojc+zgCtA5UsZBCHGtcsyr2zccmK21zsLU4BPFaToE0PTK3cCw1kF8snw/e4+fr+xRCSFEledQUgOtdRG5/MXVIDdXM/63SDxrODJheDg+bk48fX0YkfFJ/LX9KHN2HGNp1ElcHO3o27Q2Q1sH0ruJPy6O9iSlZnHPlI1kZOUw/d4OePzyNNTtBHXal20wwd2h5c2w+kNoe4cp4+DkAfU6WfemhRCiavgSkxBtO7BCKdUAkD+clsS/GdQMhag5vDZiLKujT/OfmduZ9VA3HOwlO7QQQpRViYGfUqpnYce11iusPxxRWj9uOMzWw2f538jW+Lg5AaCUolVdb1rV9Wb8wGZsPnyGv7YfZV7kMeZGHsPd2YH+LWpzOCGVwwmpTL2vE43PrYUzB6Hvy+Ub0PVvwN75sPBFOLoNQnqBvaMV7lQIIaoWrfXHwMcFDh1SSkmmq5IoBc2GwNpPqWmXwmvDWvDYT1v5dvVBHugZWtmjE0KIKqvEwA8ouBHdBegEbAb62GREwmInzqXz7vwoujfy5aa2dQptY2en6Bhck47BNXllSHPWHkjgr+1HWbDzOOfSs/loVBu6hPjC95+DRxA0G1ZoPxbzqgs9noZlb5rXPZ4qX39CCFFFKaW8gFeB/D+g/gO8AUiStJI0G2a2DexbxJBWI/lr+1EmLtpHv2a1CfFzr+zRCSFElVTimgmt9dACj+uBlsAZ2w9NlOSNv3aTkZPLm8PDsST3joO9HT0a+/HuLa3Z+FI/Vvw7ghvb1IETu+HgP9DpfuvMznV9DLwbmK9lf58Q4tr1LXAeGJn3OAd8V6kjqiqC2oFHIOyZjVKKN4e3xNnBjudnRZKbK9skhRCiLMqyWD4OaGbtgYjLJMXB9NsgKb7Qt5dFnWBu5DEe79OIhrXcSt29s4M99X1dzYv1X4CDi8nMaQ2OLjDia+j1vEnNLYQQ16ZQrfWrWusDeY/XgZDKHlSVYGdnkrxEL4XMVPw9XXhpSHM2xCby4/pDlT06IYSokkoM/JRSk5RSH+c9PgFWAlss6VwpNUAptVcpFa2Uer6Q9z9QSm3Le+xTSp3NO95GKbVWKbVLKbVDKXVbaW+sylvyGuxbALt+u+KtlIxsXv5jF4393cu/3yE1EXb8DK1Gmnp81lK/M0SMt15/QghR9aQppa7Lf6GU6g6kVeJ4qpZmQyA7DWKWAXBr+7r0aFyLt+dHEXcmtXR95WRDjmUljoQQorqyZMZvE2ZP32ZgLfCc1npMSScppewxxd8HAs2B0Uqp5gXbaK2fyis+2waYBORHOanAnVrrFsAA4EOllLeF91T1xW2GyF/N1zHLr3j7wyX7iD+bxn9HhOPkUM4MZ5unQHY6dH6ofP0IIYS43IPAp0qpWKVULPAJpkSSsESD7lDDB/b8BZjEZW+NCAdg/G+RaG3hks+cbPhuAEwdDpaeI4QQ1ZAlUcNM4Aet9fda6x+BdUopVwvO6wRE5y1vyQRmADcW03408BOA1nqf1np/3tdHgZOAnwXXrPq0hkUvgps/tB0Dh1ZDVvqFt3fGJ/Ht6lhGd6pPx+ByztDlZMHGydCwF9RuXnJ7IYQQFtNab9datwZaAa201m2RxGiWs3eEsIGwb/6F2bq6Pq48P7ApK/ef5tfNcZb1s/FriNsIh1bB7j9tOGAhhLi6WRL4LQVqFHhdA1hiwXl1gCMFXsflHbtCXm2jhsCyQt7rBDgBMRZcs+rb8xccXgsRL5isZtnp5jWQk6t54fdIfFydeH5AU+tc61w8dJHZPiGEsBWt9TmtdX79vqcrdTBVTbOhkJ4EsSsvHLqjcwM6N6zJS3/sZHnUyeLPP3cMlk0wicb8msHSN2TJpxDimmVJ4OeitU7Of5H3tSUzfqUxCpiptc4peFApFQhMA+7RWudefpJS6gGl1Cal1KZTp05ZeUiVIDsTlrwKfk2h7VizzMXO8cL+hqlrY9kRl8QrQ5vj5WqF7JvrvwCfhtD4hvL3JYQQwhIlp2AWF4VGgKMb7Jlz4ZCdneKLMe0Jq+3OA9M2sXDX8aLPXzgecrNg8PvQ71VIjIEt31fAwIUQ4upjSeCXopRql/9CKdUeyzanxwP1Cryum3esMKPIW+ZZ4DqewFzgRa31usJO0lp/pbXuoLXu4OdXDVaCbpwMiQeg/5tg7wDO7lC/CxxYztGzaby/cC+9wvwY2iqw/Nc6uhWOrIfO/zLZ04QQQlQE2WRWGo41oHE/iJoLuRf//uvj5sSP93ehZR0vHv5xC39tP3rludFLYdfv0OMZqBkCYQOgfjf4+x3ISL6yvRBCVHOW/Mb/JPCrUmqlUmoV8DPwqAXnbQQaK6UaKqWcMMHd7MsbKaWaAj6YxDH5x5yA34GpWuuZFlyr6ks7A/+8AyER0KjfxeOhEXA8kom/rSRHa94c3tKimn0l2vEr2DtBm9vL35cQQogLlFLnlVLnCnmcB4Iqe3xVTtOhkHwc4jddctirhiPT7utM+/o+PDFjK7MK7vnLSod5z4JvI+j+hDmmFFz/BqSchLWfVuANCCHE1cGSAu4bgabAQ5gMZc201pstOC8bEyAuBPYAv2itdyml3lBKDSvQdBQwQ1+anmsk0BO4u0C5hzYW31VVtOJ9s4+h/5vmwylfqMkDkB29nCf7hVGvphVW2WoNUX+ZINPFq/z9CSGEuEBr7aG19izk4aG1dqjs8VU5Yf3Ntoc9V/ztGHdnB6bc25Guob48O3M7P204bN5Y9YFZQTN4Ijg4XzyhXkezb3DNx5BcDbaICCFEKVhSx+8RwE1rvVNrvRNwV0o9bEnnWut5WuswrXWo1npC3rFXtNazC7R5TWv9/GXn/aC1dswv9ZD32Fa6W6tCEg/A+i9NFs+Alpe8dd6nOWfxYIhbFPdd19A61zseCWcPmxpJQgghxNXMxQtCepl9foWUY3B1cuCbuzrSO8yP8b9F8tvif2DV/6DlLRDS+8r++r4KWWmw4l2bD10IIa4mliz1HKe1Ppv/Qmt9BhhnuyFdg5a8ZtJW93npircmLo5mZU4LejvsxNHOSjkBouaAsoMmg6zTnxBCCGFLTYfAmYNwcnehb7s42vPF2Pb0b+ZPrRUvkokT3PDfwvuq1Rja3QmbvoWEayNhuBBCgGWBn70qsKksrzC7k+2GdI05vM7UFer+BHgEXPLW9iNn+X5tLNkNI3BMOwkn91jnmnvmQP2u4FbLOv0JIYQQttR0MKAuFHMvjLODPZ+1PURP+0jeTL+ZSRvOFdmW3s+bfe7L3rT+WIUQ4iplSeC3APhZKdVXKdUXk31zvm2HdY3QGha+CB6B0O2xS97Kzsll/G+R+Hs402/IKHMw5ooyh6WXeABO7jJ/PRVCCCGqAnd/k+W6QFmHK6Sfw2HRi+jANqSE38XExft4f+FedCHLQ/EIgK6PwK7fIL7EtAVCCFEtWBL4PYcprP5g3iOSSwu6i7La9ZvJUtbnJXByu+St37bEs/vYOV4Z0gIP/2CoFWadwC//Q7Pp4PL3JYQQQlSUZkPhRCQkHiz8/eUTIPkEasgHvDeyHaM61uOT5dH8d96ewoO/bo+Dqy8sfrXQvYNCCFHdWJLVMxdYD8QCnYA+mCydojyy0s3evtrh0Hr0JW9l5+TyyfJowut4MSg8b/lnaB84tMacVx5RcyCgFfg0KF8/QgghREXKX6kSVcis39FtsOEr6Hgf1GmHnZ3ivzeFc1fXBny98iCvzt5Fbu5lwZ2LJ/R6DmJXmpp/QghRzRUZ+CmlwpRSryqlooBJwGEArXWE1vqTihpgtbXhS5NZ84Y3wc7+krf+3HaUw4mpPN638cWafaF9IDsNjhRay94y54/DkQ3mr6ZCCCFEVeLTwPzh8vJ9frk5MOcpcK0FfV6+cNjOTvHasBaM69GQqWsPcc+UjSzYeZyM7JyL57a/B3yCYcmrlxSIF0KI6qi4Gb8ozOzeEK31dVrrSUBOMe2FpVISYMVEaHzDFamm82f7mgd60q+Z/8U3GnQ3dYzKs9wzai6gZX+fEEKIqqnZUPMHzPPHLx7b/B0c3QI3TIAa3pc0V0rxwqBmjB/YlF1Hk3jwh810fHMJ43+LZP2BBHLtHE2weGInRP5SwTcjhBAVq7jAbwRwDFiulPo6L7GLleoJXOP+eRsyk6H//13x1pwdxzh4OuXS2T4AZ3eo17mcgd8cqBkC/s3K3ocQQghRWZoNBXTeHzKB5JOw5A1o2BPCby30FKUU/+oVyrrxfZlyT0f6NPXnj63x3PbVOnq8u5x34pqT7tfKZPgs73YKIYS4ihUZ+Gmt/9BajwKaAsuBJwF/pdTnSqn+FTXAauf0flM7qP1d4NfkkrdycjUfL9tP0wAP+jevfeW5oRGm+HryqdJfN+0sHFxhZvuUxO9CCCGqIL+mUDP04j6/RS9BVioMmljiZ5uDvR29m/jz4ai2bHqpHx/e1oZG/u58tTKWe+OHQNIR1v78DseTJPgTQlRPliR3SdFaT9daDwXqAlsxmT5FWSx+FRxqQO8XrnhrbuQxDpwys312hRVrD+1jng/8Xfrr7l8Eudmyv08IIUTVpZT5HDu4wuz12/GzqYPrF1aqbtycHRjetg7f39uJdeP7cv3gkWx1bEfT/V/R/+3Z3P71OpbvPWmjmxBCiMphSTmHC7TWZ7TWX2mt+9pqQNVa7CrYOxd6PAXufpe8lZurmbR0P2G13RnQIqDw8wNbQ42aZVvuuecvcA+AOh3KMHAhhBDiKtFsqPlD5sz7TGKWns+Wqzs/D2fu6d6Qtvd+hLdKYXLIKg4npnLPdxt5+Y+dpGVKegMhRPVQqsBPlEN2pinW7lUPujx8xdvzdx5n/8lkHutTxGwfmOyfIb1M4FeamkNZaRC9BJoOAjv5JxdCCFGFBbUDjyDIyYBB74OjlUoLB7ZCtRpJpxM/s3RcI8b1aMi0dYcY+skqdh1Nss41hBCiEkkUUBGO74Sv+8CxbXD961d8SOXmaj5eup9QPzcGhQcW31doH0g+DidLUUoxZrnZAyHZPIUQQlR1dnbQ699miWfj663bd8SLoHNxXvkuLw5uzrT7OnEuLYvhn67m6xUHrqwFKIQQVYgEfraUkw0r/wdf9YbkEzB6BrS8+Ypmi3YfZ++J8zzetzH2Rc325QuJMM8Hlls+jqg54OwFwT0sP0cIIYS4WnW4F65/w/r9+jSAjuNg249wMooejf1Y8GRPIpr4M2HeHsZ+u16SvwghqiwJ/GwlIQa+GwBLX4emg+HhddBk4BXNtNZ8tDSakFpuDGkVVHK/3vWgVpjl+/xysmHvfGgyABycSnkTQgghxDWmxzPg5G4yhmpNTTcnvhzbnrdGhLPl0FkGfLSCBTuPl9yPEEJcZSTws7bcXFj/FXze3ZRuuPkbuHUKuPkW2nzx7hPsOXaOR/s0Knm2L19IBMSutqze0OE1kJYoyzyFEEIIS7j5Qu/nIXrxhbIRSilGd6rPnMevo56PKw/+sJnnZ+0gJSO79P2nnYUvesDGb6w8cCGEKJ4EftZ09ghMGw7z/w3B3c0sX/gtRdYW0trU7Qv2dWVYawtm+/KF9oHsNDiyruS2e+aAgws0kkSsQgghhEU6/Qtqt4T5z0NG8oXDoX7uzHqoGw/1DuXnTUcYMmkV24+cLV3fi1+B4ztg6RuQcd7KAxdCiKJJ4GcNWsPWH+HzbhC3CYZ8CHfMBM/iE7UsizrJzvhzPBLRCAf7UvxTBF8Hdo4maUtJ44qaC6F9wcnN8v6FEEKIa5m9Awz+H5yLgxXvXvKWk4Mdzw1oyvT7u5CelcPNn6/h0+XR5FiS+OXgCtjyPYQNgPSzsOErG92AEEJcSQK/8ko+CTNuhz8fhoBweGg1dLinyFm+fFqbTJ71atZgeNs6pbumszvU61zyPr+jW82HVjNZ5imEEEKUSv3O0HYsrP200EzaXUN9WfBET25oEcB7C/dy6xdr2HeimBm8zFSY/TjUDIFbvoPG/WHNJ5fMKAohhC1J4Fcee/6Cz7pA9FLoPwHumgM1G1p06t/7TrE9LolHIxrhWJrZvnyhEWapSPKpottEzQFlb/6yKIQQQojS6fc6OHvA3GcKrZ/r5erIJ7e35YPbWnPwdAqDP17JxEV7Sc8qpOj73/+FMwdh6Mfg5Aq9njN78DdOroAbEUIICfzKLuU0/HIXeNWFf62Abo9aXBxda81HS/ZTx7sGN7WtW7brh+aXdfi76DZ75pi9hq41y3YNIYQQ4lrm5muCv0OrYcfPhTZRSnFT27oseboXQ1sFMWlZNAM/WsnamISLjeK3mJnD9ndDw7zSSnU7mK0YayZBZort70UIcc2TwK+sTu0FnQN9XwX/pqU6deX+02w7cpaHI0JxcijjP0FgG6jhU3Q9v9P74fReaDq0bP0LIYQQwiz3rNsRFr4IaWeKbObr7sz/bmvDtPs6kZOrGf31Op6buYOz51Ng9mPgXvvK2oO9n4fU07DpWxvfhBBCSOBXdgnR5tm3UalOM3X79hPk5cIt7cs42wdgZw8hvc0+v0KWn7DnL/PcdHDZryGEEEJc6+zsTKKXtERY+n8lNu/R2I+FT/bkwV6hzNwSx/QPnoETO9GDJ4KL16WN63Uyn+WrPzJ7AIUQwoYk8CurhGiwdzZLPUthbUwCmw+d4aHeoTg72JdvDKF94PwxOBV15XtRcyCoHXiVMnGMEEIIIS4V2MqUeNj0LcRvLrF5DSd7nh/YlAVjajMu91fm5HThnrV+HEksJLjr9TyknILNU6w/biGEKEACv7JKiDGZuexKF7x9uHQ/AZ4ujOxYr/xjCMnb53d5ds9zR80Hk2TzFEIIIawj4gWzXHPO05BbSPKWy+Xm0njtCzi4uHOu9wQ2HEyk/wcrmLzyANk5uRfbNegKwT1g9YeQlWa78QshrnkS+JVVQjT4hpbqlHUHEthwMJEHe4WUf7YPwLse+Da+sp5f1FzzLPv7hBBCCOtw8YQbJsCxbZbtydv0DRxZhxrwNrf37cDip3vRNdSXN+fu4abP1rD76LmLbXs/D8knYMtU241fCHHNk8CvLHJzIPFAqff3fbRkP/4ezozqVN96YwntA7GrIDvj4rE9s6FWGPiFWe86QgghxLWu5c3QsJfZ65d8suh2Z4/AktfMZ3TrUQDU8a7BN3d14JPb23IsKZ3hn67mqxUx5OZqCL4OGnSHVR9AVnrF3EtZ5eZC7OrC8wsIIa5qEviVxdnDkJtVqsAvMi6JtQcSeKBnCC6OVpjtyxfaB7LT4PA68zo10fxAbirLPIUQQgirUgoGT4SsVFj0cuFttIY5T5nnIR+acy6crhjSKohFT/Ukoqkf/50Xxe2T1xF/Ns3U9Tt/DLZOK/84UxPL30dRNn0DUwYVWd5CCHH1smngp5QaoJTaq5SKVko9X8j7HyiltuU99imlzhZ47y6l1P68x122HGepJcaY51IEfjM3H8HJwY5bO1hhb19Bwd3BzuHiPr99C0yZCdnfJ4QQQlhfrcbQ/QnYMcOsuLlc5K8QvRj6vgI+DQrtoqabE1+Mac+7t7QiMi6JAR+u4M+kUKjXxcz6FVzFU1obv4F3Q2DtZ2XvoygZ5+Gfd8zX/7wDOdnWv4YQwmZsFvgppeyBT4GBQHNgtFKqecE2WuuntNZttNZtgEnAb3nn1gReBToDnYBXlVI+thprqSWULvDLzM5l9vaj9G9eG68ajtYdi7MH1Ot8sZ7fnjngWcdk9BRCCCGE9fV4Brzrw9xnIDvz4vGU0zD/OajbCTqNK7YLpRQjO9Rj/hM9CavtwRM/b+cTfQuci4etP5RtXKs/grlPg2MN+PstMx5rWvupyUDa4xmz5SXyF+v2L4SwKVvO+HUCorXWB7TWmcAM4MZi2o8Gfsr7+gZgsdY6UWt9BlgMDLDhWEsnIRqcvcCtlkXNl0Wd5ExqFjeXp25fcUIj4Nh2OHMIYpaa2n0FlpYIIYSoOsqzWkZUECdXGPieKae0rsDM2vznIDMZhk2yOOt3fV9Xfn6gC89cH8aHB4KIVGFk/P3+pQFlSbSGZRNg8SvQYgTctxgyU2D5hFLeWDGST8GaSdD8RujzMgS0gn/ehZws611DCGFTtgz86gBHCryOyzt2BaVUA6AhkF+XwOJzK0V+Rk8Lg6tZW+Lw83CmRyPLAsVSC+1jnhe/DNnpsr9PCCGqqPKslhEVrMkAaDLYLHk8exj2LoCdM6Hnv8G/aam6crC347G+jfnt4e784Dwa55SjzP1hIhnZFpSN0BoWvgAr3oW2Y+DmyRDQEjreb2oDnthdtvu73Ir3TLmJPq+Y338iXoAzB2H7DOv0L4SwuaslucsoYKbW2oKfcBcppR5QSm1SSm06deqUjYZWiIRoi5d5JiRnsDzqJDe1rYODvY2+3YFtwMUbdv8JNXxMZjAhhBBVUXlWy4iKNvBt8zznKbPE0r85dH+yzN21quvNq089RpxrM1od+IYRk/4h6vi5ok/IzYG/Hjezjp0fgqEFZhp7Pw/OnrDoxfJn4Ew8YEpYtLsTauX9/hM2AILamoBQZv2EqBJsGfjFAwUzmdTNO1aYUVz6wWXRuVrrr7TWHbTWHfz8/Mo5XAtlpZs0zRYGfrO3HyU7V3NzOxst8wTzQz6kt/m6ySCwd7DdtYQQQthSeVbLiIrmXR96/Qeil5iMnMM+AQencnXp6uxI3eGvU8/uFJ3PL2LYpNV8veKAKftQUE4W/DbO1P7r+W8Y8BbYFfi1zrWmyRQaswz2Ly7XmFg2AewdTTCZTynoPR7OHoJt08vXvxCiQtgy8NsINFZKNVRKOWGCu9mXN1JKNQV8gLUFDi8E+iulfPKSuvTPO1b5zhwEtMXF22dtiaNlHU+aBHjYdlzbFgAJAAAgAElEQVT5yz1lmacQQlwril0tU2mrYq41XR4xtf0iXoC67a3TZ+P+ENiGFz3m0SfMhwnz9jB40iqW7D6B1tr8EfrnsbBzFvR7Hfq8VPj2k473Q81QsxS0rLNyR7eZJaxdHgaPgCvHWac9rCjlnkQhRKWwWeCntc4GHsUEbHuAX7TWu5RSbyilhhVoOgqYofXFdQha60Tg/zDB40bgjbxjlS8h2jxbMOMXdfwcO+PP2Xa2L1/rUXDTl2bphRBCiKqqPKtlLlEpq2KuRQ5OcNdsM+tmLUpBr+ewTzrE561i+Hh0W9Iys7l/6iZGf7qUs9/cBPvmm5qC1xWztNTBCW6YAAn7zVLNslj6OtSoCd0fL3ycvV+ApMOw7cey9S+EqDA2XROotZ4HzLvs2CuXvX6tiHO/Bcr4U8qGLgR+Jc/4zdoch4OdYljrIBsPCnBwNsGfEEKIquzCahlMwDcKuP3yRkWslhHVSZOBEBCOWvk+wx65jYEtA5i9bjdhS+7FI3cfn/o8Sxf/EZQ4xxg2wMxI/v0WtBppcgFYKma5WSp6w3/BxavwNo36Qt2OZtavze3m9xEhxFXpaknuUnUkRIN7bVM/rxjZObn8vvUoEU398XWXH4JCCCFKVp7VMqKayZv1I/EA7JyFY3oiN0c+SEt1gH9av893yV25+fO13PPdBnbGJxXfzw3/hfQkU37BUrm5sOQ18KpvlowW13/v8XAuDrZOs7x/IUSFkywgpZUQY9Eyz5X7T3M6OYNbbFW7TwghRLVUntUyopppMhhqt4R/3oaV78PZI6jbZ9CnUT9WDMnm+zWH+OKfGIZMWsWg8ACevj6MRv6F/GE6oCW0HQsbvoIO90KtxiVfe/fvcGyb2UZS0ixeaB+o1xlW/s9cR2b9hLgqyYxfaeXX8CvBzC1x+Lg6EtHEvwIGJYQQQohqx87O7B1MPADnjsGYWdCoHwCuTg481DuUlc9F8Hjfxvyz9xT9P1jB079s43BC6pV99XkJHGrAopdLvm5OFiz9P/BvAeG3ltz+wqxfvMkyKoS4KkngVxppZyHlVIkzfkmpWSzefYIb29TByUG+xUIIIYQoo2bDoO+rcM9cCL6yTq+niyNPXx/Gyuf6cH+PEObuOEafiX/zyPQtrI4+fbEMhLs/9HzGJIU58Hfx19w8xWQx7/faxbqAJQnpDfW7wcqJJuuoEOKqI1FJaSTGmOcSAr85kUfJzM6tmGyeQgghhKi+7Oygx9MQ2LrYZjXdnHhhUDNW/ieCu7sFszr6NHdMXk/ExL/5/O8YTp3PMEXevevDghdM8ffCZCTDP+9Ag+ug8fWWj1MpiBhv6hlunmL5eUKICiOBX2kkWBb4zdocR1htd1rW8ayAQQkhhBBCGP6eLrw0pDnrxvflo1FtCPRy4Z0FUXR9aykP/byL3S2fhZO7il6SufZTs7qp32uF1wYsTsOeJmBc9T/ISivvrQghrEwCv9JIiAZlBz7BRTY5cCqZLYfPcnO7uqjS/sAUQgghhLACF0d7bmxThxkPdGXpM72497qGrD+YyKAlvmy3a0bqwjc4derUpSelnIY1H0OzoVCvY9kuHDEekk/Apu/KfxNCCKuSwK80EqLNEolislX9tiUeOwU3ta1TgQMTQgghhChcqJ87LwxqxtrxfZg0uh2/+D6Ma1Yisz5+mn9N28TyqJOkZGTDivfMTF3fV8t+seDrzMzfqg8gs5AkM0KISiOBX2kkRBe7zDM3V/P71nh6NPbD39OlAgcmhBBCCFE8Zwd7hrYOYsIjd3K+ya3c7zCfowejuGfKRga+NpWs9ZNZ7TmQL3bZsXL/KRJTMst2od4vQMpJ2PStdW9ACFEuUsfPUlqbPX71uxbZZN2BBOLPpvHcwKYVODAhhBBCiNLxGPwGHJjLH40Ws6L1ewQufYzc0/a8mz6c7fOjLrQL9HKhRZAXLYI8zaOOF0FeLsVvZ2nQ1WT5XPUBdLgHnNxsdyPJp+D49gtlLoQQRZPAz1LJJyAzudgZv5mb4/BwcaB/89oVODAhhBBCiFLyDILuT2L/93+JCO4GpxbAdU/zZ79bOZOSye5j59h1NIldR8+xMz6JpVEn0HmVIfw9nJk0ui2dQ3yL7r/3C/Btf9g4Gbo/YZt7yEiGacPhxE4Y+hG0v9s21xGimpDAz1IJ0ea5iOLtyRnZzN95nOFtg3BxtLDmjRBCCCFEZen2GGz5Hub/B1y8LwRoPm5OdG9Ui+6Nal1ompqZzZ5j59l9NInv1sRyz5SNTL23Ex2Caxbed/3OENoXVn8EHe4DZ3frjj03F37/F5zcbUpdzH0GfBpCSC/rXkeIakT2+FnqQuBX+Izf/MhjpGXlSO0+IYQQQlQNTq6mbANAz2ehhneRTV2dHGjfwIexXYOZMa4LAZ4u3PXtBrYcPlN0/xEvQGoCbPzaqsMG4J+3IWoO9J8Ad/1lfj/7ZSycjrb+tYSoJiTws1RCNNg7g2fhgd2sLXEE+7rSvoFPBQ9MCCGEEKKMwm+FB1dB10ctPsXf04Xp47rg5+HMXd9sYPuRs4U3rNsBGl0Pqz+Gc8esNGBg1++myHybMdDlIXDxgtt/BjsHmH4rpCZa71pCVCMS+FkqIcYs87S78lt2JDGVdQcSGSG1+4QQQghRlSgFAeGlLtYe4GWCP283R8Z+s56d8UmFN+z3KuRkwjf94fT+8o/32Hb4/SGo1xmG/O/iuH2CYdR0SIqDX+6E7DJmJBWiGpPAz1IJ0UXu7/t9azwAI9pJ7T4hhBBCXBuCvGvw07gueLg4csfk9ew6WkjwFxAOd8+B7DQT/MVtLvsFk0/CT7eDa0247Ycr6yrX7wLDPoHYlTD3KS5koxFCABL4WSYnGxIPFrq/T2vNb1vi6BriS10f10oYnBBCCCFE5ajr48qMB7rg5mTPmMnriTp+7spGQW3h3oXg4gnfD4H9S0p/oewM+HmM2TM4ajq4+xfervVt0PPfsPUHWDOp9NcRohqTwM8SSYchN6vQwG/zoTPEJqRyc3tJ6iKEEEKIa0+9mq5MH9cFZwd77vh6PftPnL+ykW8o3LvIPP90G2yfYfkFtIa5T8OR9TD8MwhqU3z73i9A8+Gw+BWImlu6mxGiGpPAzxIJMea5kMBv1pY4XJ3sGdgyoIIHJYQQQghxdQiu5cb0cZ2xt1OM/no90SeTr2zkURvungf1u5pSDKs/tqzz9V+aGbye/4GWI0pub2cHwz83M42z7jf7AoUQEvhZpIhSDulZOczZfowBLQNwc5aSiEIIIYS4doX4uTN9XBcAbv96HQdPp1zZyMUTxszKm5F7GRa+aGryFSVmGSwcD02HQO/xlg/GyRVG/wQ1fGD6KOtmFRWiipLAzxIJ0SZVsKvvJYcX7jrO+YxsbpHafUIIIYQQNPJ3Z/q4zuTkakZ/tY5DCYUEfw7OcMu30HEcrP0E/ngQcrKubJcQA7/eDX7N4KYvC82sXiyPABg9A9KTYMZoyEwt0z0JUV1I4GeJhGgz23dZquNZW+Kp412DLiG+RZwohBBCCHFtCavtwY/jOpORncPor9ZxJLGQgMvOHga9B31egh0/w/TbIKPA8tD0JPhpFCh7GD0dnN3LNpjAVnDzZDi6zQSYxc0uClHNSeBniYSYK5Z5JqZksmr/KYa3DcLOTmr3CSGEEELkaxrgyQ/3dyYlM4cRn6/h0elbeGveHqasPsiiXcfZGZ9EYmoWusezMPRjOLAcpg6DlATIzTF78xIPwG3TTI2+cg1mEPT/P9j9JyyfYJX7E0D8Zvi6D/w02uzBTDld2SMSJZCNaSXJSoOkI1cEfhsOJpKrIaJJEemEhRBCCCGuYS2CvPjx/s68syCKyPgkFu06QWbOpTNuLo52BHk1YEjNl3ns6Fucn9Sbs/6dCDm8CIZ8AMHXWWcwXR+F0/tg5ftmCWir28x+Q1E2O36F2Y9CjZpw/gTsnQfKDup1MYF2k0FF1r++amRnwLEdULfDFav6qisJ/EqSeMA8X/afd2NsIk4OdoTX9aqEQQkhhBBCXP1a1vFi2n2dAcjN1SSkZHIsKY2jZ9M5ejbtwtcrkzoTZf8K76X9l5DDM5mafT1fLQ2m68HtdGvkS9eQWgR4uZR9IErBoImmLvO8Z82jZqgpDRHYJu+5tcnpYKnMFDgVBSf35D12m+fsdPCun/dokPeoDz55z05uZb+PypabC8vegFUfQIPuMHKqyYFxfIcpnRE1Dxa9ZB5+zaDpYBMIBrW7uoKrjPNmpjJ2JTQbamadXWtW9qhsTgK/khSR0XNjbCJt6nnj7GBfCYMSQgghhKha7OwUfh7O+Hk406rQvHjdyTrel1NbZ4PHzbQ4mMSi3Sf4dXMcACF+bnQN8aVbaC26hNTE1925dANwcDIZRQ+uMHv+jm2Dw+th56yLbWqGFAgE84JBR1fz++DJ3ReDu5O74cwhQOf1XQP8mkBIBDi6wNnDcGov7F9sAsGCXGtdGgjW7QRhN4C9Y+nup6Kln4PfHoB986H9PTDwXfM9BfN9CmwNES/AmVjYO98Egqs+yJtlDYImA00g2LAX2FdiCJKSAD/ebGb72o4xNSXje8DNX0ODbpU3rgqgtNaVPQar6NChg960aZP1O145EZa+AePjL2wsTs7IptVrC3kkohHP9G9i/WsKIYQollJqs9a6Q2WPo6qw2WekEDaWk6vZc+wca2MSWBNzmg0HE0nJzAGgaYAHXUN9iWjiT4/GtVBlnVFKPmVq/R3bmhcQbjfbfPIpe9Dmmtg5gG9j8G8G/s3znpuZfYh2hUwGaA3JJ00gePZQ3uOwCRrPHjbXyckENz9oPRra3Qm1GpftPmwp8YCZITu9Hwa+Ax3vt2wGLzUR9i2EvXMheilkpZogsN1YaDsWvOvZfuwFJcXDtJvMv8Ot30OTAWav4sz7zLFez0HPfxf+b1lFFPf5aNPATyk1APgIsAcma63fLqTNSOA1zJ9Mtmutb887/i4wGJOAZjHwhC5msDb7UPvjEYheAs/uvXBoxb5T3PntBqbe24meYX7Wv6YQQohiSeBXOhL4ieoiKyeXyPgk1sYksDYmgY2xiWRk59KuvjfjBzWjY7CVluulJJgZwWPbzJLO/CDPt5EpR2EtOdkQsxS2TIV9CyA32+yTa3cntBh+dSwLPfAP/HqX+frW7yGkV9n6yUozv1Nv/t48AzS+3sweNu5v+1nAhBiYOhzSzsDtMy7dP5pxHuY+YzLMNugOI74Cr6pZrq1SAj+llD2wD7geiAM2AqO11rsLtGkM/AL00VqfUUr5a61PKqW6Ae8BPfOargLGa63/Lup6NvtQ++YG89ede+ZeODRx0V4+XR7NjtduwF0KtwshRIWTwK90JPAT1VVGdg6/b4nngyX7OHEug37N/PnPgKaE1fYod99aa3bEJXEsKY3mgV7Uq1mj7LOKlkg+Cdt/MkFgQjQ4eUDLEdDuLqhTCXvktIaNk2H+c2YWcvRPZimsNZw9bO5zyzRIPg4egWYGsN2dtpkFPB4J00aYmdsxsyCobeHtts8wAaCdA9z4idn/V8UU9/loy6ilExCttT6QN4gZwI3A7gJtxgGfaq3PAGitT+Yd14AL4AQowBE4YcOxFi0h2qxHLmDDwURa1vGSoE8IIYQQohI5O9gzqlN9bmxTh29XH+SLv2MY8OEKbmlfl6euDyPQq0ap+zx5Lp3ftsYzc3Mc0Scv1hb0quFIyzqetAzyomUdL8LreNHA19V6waC7P3R/Aro9DofXwdZpEPkrbPnezDi2HWuykbpVQP3o7EyY/x/Y/B2EDYARX1s3C6p3fVPDsdfzsH8hbPoOVrxnHo2vh/Z3Q+MbrDMLeHg9TL8VnNxh7FzwCyu6betRULcjzLwXfh4DHe6DGyaAY+n/H12NbBm51AEKLJAmDuh8WZswAKXUasxy0Ne01gu01muVUsuBY5jA7xOt9R4bjrVwaWcg9fQliV0ysnPYeuQsY7s0qPDhCCGEEEKIK9VwsueRiEbc3qk+ny6PZuraQ/y57Sh3dw/m4V6N8HItPnFKRnYOS3afZObmI/yz7xS5Gjo08OHtEeE0DfRk99FzRMYnsTM+ie9Wx14oS+Hh4kCLIE/C65hgsGUdLxr6upWvxrNS0KCreQx42ySf2ToNFo6HJa9CaB8THDXubwIoa0s5Db/cBYdWQfcnoe8rttvzZu+Ql/lzcN4s4DRzrzNuvzgL2HpU2UtDRC+BGWPAMwju/MOy75dvKNy32GQvXTMJDq+FW741S32ruMqesnIAGgO9gbrACqVUOFALaJZ3DGCxUqqH1nplwZOVUg8ADwDUr2+D//gJ+aUcLgZ+kXFJZGbnWm8NuRBCCCGEsAofNydeGtKcu7sH879F+/hqxQFmbDjCIxGh3Nk1GBfHiwGM1prI+CRmbo7jz21HSUrLItDLhYd6h3JL+3o0rHVxf12bet4Xvs7MzmXfifPsjE+6EAx+v/YQmdkmGGwa4MFnd7QjxM+9/Dfk4gkd7jGPE7tMofSouWY/IIBf04tBYL0uF7NsloXWpizDz2NMbb4RX0OrkeW/B0t514c+L5oEK/sXwuYpebOA70Kd9hA+0ix9dbewhvau32HWOPBvCmN+s/w8MN/H/m9CSG/4/UH4qjcMeMvsR7yaylKUki33+HXFzODdkPd6PIDW+q0Cbb4A1mutv8t7vRR4HhMIumit/y/v+CtAutb63aKuZ5P9C9t/ht8fgEc2XpgW/uzvaN5dsJfNL/UrfRphIYQQViF7/EpH9viJa9Xuo+d4d2EUf+89RZCXC09dH0bPMD9mbzvKzM1x7D1xHmcHO25oEcCtHerSLbQW9mWYrcvKyWX/iWS2HD7DxEV7yc7RvD+yNTe0CLD+TWlttiLtX2TKRRxabTKDOrmbQKVxfxMMegYVfm5qgsnSmRBjnhPznhMOQEYSuAfA6Okm2KpsSfFmxjPyF7NPT9mbe2w10swSOhexl3Pz9zDnSajXGUbPgBrehbezxPkT8MeDELPMLHttOxZCI66OxDuFqKzkLg6Y5C59gXhMcpfbtda7CrQZgEn4cpdSqhawFWgD9MPs/xuAWeq5APhQa/1XUdezyYfasgmm9siLJy78BeWe7zZw5EwaS54uY0YjIYQQ5SaBX+lI4CeudWtiTvPO/Ci2xyVdONa2vje3tq/H4FaBeNWwXg29+LNpPPTDZnbEJfFgr1Ce7R+Gg72d1fq/QkayqU2YHwieM3UPqd0SGvUz9QEvBHoHTXCXT9mBVz2TtMU31BS1b3kzeNS23XjL6mSUCQAjfzXLQh1qmOLw4SOhUd+LdRBXfwSLXzH3PnIaOLmW/9q5ubD2E1jxvvn+2TtDw56mHETYQPCqU/5rWElllnMYBHyI2b/3rdZ6glLqDWCT1nq2MrthJ2ICvBxggtZ6Rl5G0M8wWT01sEBr/XRx17LJh9qv98DRrfDENsDUkmnz+iKGtA7irRHh1r2WEEIIi0ngVzoS+AlhlnYu2Hmc/SeTGRQeSCN/KyzFLEJ6Vg6v/7WbnzYcpluoLx+Pbkutcq4US0rNYvqGwzQL9KB3kyKWLWoNp6IuBoGH14LONcsoa4aYwO5CkBcC3g3Ktzy0MmgNR9bDjl/Mcs60RKhRE1rcZLJxbvgSWoyAm760/r3lZJnv6d755nHmoDke0MoUqA8bAIFtwM6CQD8rPa+mY6zp50ysmbkdPLFcQ6y0wK8i2eRD7Yse4F4bxswEYNfRJAZ/vIoPbmvNTW2rZm0PIYSoDiTwKx0J/ISoHL9sOsLLf+ykppsTn93Rjrb1fUrdx5mUTL5dfZApq2M5n5GNg51i0ui2DAwPLPnkzFQTDFW14M5S2ZlmCWbkLxA1D7LTzD68wRNtX4Rdazi9D/bOg70LIG6DCbI9AiHsBjMTGNjKLFctGNydiTUzr+ePXtqfo6vZs/nA8nINq7LKOVRtWpsp8QbdLxzaeDARgE4NKyCNrhBCCCGEqNJGdqhH80BPHvpxMyO/XMurQ1twR+f6FpWASEjOYPKqg0xdE0tKZg6DwgO4t3tD3pofxWM/beUTBQNalhD8WWOZ49XMwckst2wywBRhP7Eb6nWqmAQsSoFfE/O47ilISTAzrXvnQeRMk5zmch6B4NPQ7FP0CTaPmg3Ns5ufzcctgV9Rzh+HrJRL0sduiE2kjncN6nhXj1oeQgghhBDCtlrW8eKvR6/jyZ+38dIfO9ly+AwThodTw6nwGalT5zP4euUBpq09RHp2DkNaBfFoRCOaBJhEJlPu6chd327g0elb+eR2xYCWNkggUxU5e0D9yyvHVSA3X2gz2jyyMyB2ldlb6V3fBHbe9Su9HqAEfkVJiDbPeaUctNZsOHiG6xrJbJ8QQgghhLCct6sT397VkY+X7eejpfvZffQcX45tTwPfi5khT55L58sVB/hxvSkNMax1EI/2aUQj/0szV3q4OPL9vZ3ygr8tfHJ7Own+rjYOzibhDH0reySXsGGKoSrussAvNiGV08kZssxTCCGEEEKUmp2d4sl+YXx7d0eOJaUzZNIqlu45wbGkNF6bvYvr3l3OlDWxDA4PYsnTvfhwVNsrgr58+cFfq7pePDp9Cwt2Hq/guxFVkcz4FSUhGhxcwNOkZ724v6/0m3KFEEIIIYQAiGjiz5zHruPBHzZz3/ebcLK3I1drbm5Xl4cjQi+ZBSxOfvB3Z97M36d3tLNN3UBRbUjgV5SEGJPyNi8d6/qDidR0cyLUz3apf4UQQgghRPVXr6Yrsx7qxtvzo8jOzeVfPUOpV7P0iVg8XByZmhf8PfKjBH+ieLLUsygJ0ZckdtkYm0iHBj4WZWESQgghhBCiOC6O9rw2rAVvDg8vU9CXL3/mL7yuF4/8uIVFu2TZpyicBH6Fyck2tTby9vcdT0rncGIqnRrWrOSBCSGEEEIIcSnPvOCvZR0vHpkuwZ8onAR+hTl7CHKzLwR+G2Lz9/dJ4CeEEEIIIa4+ni6OTL2vEy2CTPC3ePcJi889n55FZFwS8yKPEX3yvA1HKSqT7PErTEKMec4L/DYeTMTNyZ7mgZ6VOCghhBBCCCGKlh/83fnNBh7+cTOf3dGe65vXBiA5I5vY0ynEJqQQezqFg6dTOZRgXp9Ozrykn7Da7gwKD2RQeCBhtQvPLCqqHgn8CnNZKYeNsYm0a+CDg71MkAohhBBCiKtXfvA3Ni/4a1PPm9iEVE6dz7iknb+HM8G13OjbtDbBtdxoWMuVIO8abDl0hnmRx/lo6X4+XLKfRv4mCBwcHkhYbXfJd1GFSeBXmIRocPEG15qcTc1k74nzDA4PrOxRCSGEEEIIUSJPF0em3deJ52bu4HRyBr3D/PKCOzeCfd0IruWKq1PhYUCrut7c3b0hJ8+ls2DXcebuOMakZfv5eOl+Qv3cLswENg3wkCCwipHArzAJ0Wa2Tyk2xZ5Ba+go+/uEEEJUAKXUAOAjwB6YrLV+u5A2I4HXAA1s11rfXqGDFEJc9TxdHPl8TPsyn+/v6cKdXYO5s2swJ8+ns3DXCebtOMany6OZtCyakFpuDAwPYHB4EM0CJQisCiTwK0xCDARfB5hlno72ijb1vCt5UEIIIao7pZQ98ClwPRAHbFRKzdZa7y7QpjEwHuiutT6jlPKvnNEKIa4V/h4ujO3SgLFdGnA6OYOFu44zL/IYn/8dw6fLYwjxc2NIeCCDWwXRJED2BF6tJPC7XGYqnIu7JKNn67reuDjaV/LAhBBCXAM6AdFa6wMASqkZwI3A7gJtxgGfaq3PAGitT1b4KIUQ16xa7s7c0bkBd3RuQEJyxoXloJ8sj+bjZdE09ndncKtAhrQKopG/e2UPVxQggd/lEg+YZ99Q0jJziIxLYlzPkModkxBCiGtFHeBIgddxQOfL2oQBKKVWY5aDvqa1XlAxwxNCiIt8CwSBJ8+ns3DncebsOHYhMUzTAA8GhwcypHUQDWu5VfZwr3kS+F2uQEbPrYfPkJ2r6RQs+/uEEEJcNRyAxkBvoC6wQikVrrU+W7CRUuoB4AGA+vXrV/QYhRDXGH8PF8Z2DWZs12BOnEtnfuQx5uw4xsTF+5i4eB/NAz0Z3CqQ3k38aBbgiZ2d7AmsaBL4XS4/8KsZwoZdR1EK2gf7VO6YhBBCXCvigXoFXtfNO1ZQHLBea50FHFRK7cMEghsLNtJafwV8BdChQwdtsxELIcRlanu6cHf3htzdvSHHktKYF3mcOTuO8t7Cvby3cC8+ro50DfWlW2gtujeqRbCvqySHqQAS+F0uIQY8AsHZnY2xiTQL8MTTxbGyRyWEEOLasBForJRqiAn4RgGXZ+z8AxgNfKeUqoVZ+nmgQkcphBAWCvSqwX3XNeS+6xpyPCmdNTGnWR2dwJqY08yLPJ7XxoVuobXoFupL90a1CPByqeRRV08S+F0ur5RDVk4uWw6d5baO9Uo+RwghhLACrXW2UupRYCFm/963WutdSqk3gE1a69l57/VXSu0GcoB/a60TKm/UQghhmQAvF0a0q8uIdnXRWhObkMrq6NOsjUlgWdQJZm2JAyDEz41uob50DalFkwAP6td0xcnBrpJHX/VJ4He5hGhoPoyd8UmkZf1/e/ceHFd53nH8+2gly7rY8hXXN1m+kdrGxja+kARSCi25TBgu6YBN3CGdpqRJYCBMMlD+cGmmaTOk7VAXD40ZYAiGAlMugQklOJAJIanvCBtfwDf5KrBsIduyLaHL0z/2mCzCMlato7P7nt9nZmfPvnu0eh6/q/P42XP2nA7m6fp9IiLSh9z9JeClLmOLc5YduCO6iYgUJDNjfHRR+UUXj6Oz09n63rFoj+Ahnlu/n+Ur9wCQKTLGDi5jwvBKJgyrYPzwCiYMq2Ti8AqGDyiN9TDRIyfa2NN4gt2Nxynvl+FPP3NewR6WqsYv14lGONkIQyexpq4RgLk6sYuIiIiISKyKioypoyivyMIAAA1+SURBVAYyddRAvnnpBNo6Otl84Cg7GprZ2XCcXYeOs6Ohmd/vOERLW+dHP1dZWvxRA1kztJyq8n4MKC1mQP9iKvsXUxktD+hfQmVpMeX9Mh9r3Do6nQNNJ9nbeILdjSfYc+p2OHt/5GTbx+L80bUX8PX54/rs36U3qfHLdXhH9n7oJFav/IDxw7KfIoiIiIiISN8pyRRx4dhBXDh20MfGOzud+qMt7GxoZteh4+xsyDaE6/d8wIsbDuCfciqrIoOK0mIGlBaTyRj1TS20d/7hh4qLjDGDy6geWsGFY6uoHlJO9ZAKxg4p496X3+GeFzYxZeRAZlcX3skf1fjlis7o2Tl4Imvq6vjitBEJByQiIiIiIqcUFRmjB5UxelAZl04e/rHn2js6Od7awbHWNppb2znW0k5zSzvHWrP3za1tNLe0c7SlnebWdto6Ohk1o4xxQ8qzDd7QckZWlZHp5lIT/75gJlfd/wbfWb6eF2+9pOB2EKnxy3V4O1iGbW1DOXJyG/PGD006IhEREREROQvFmSKqyouoKo/njPyDyvvx00VzuO6B33HLE+tZ/s35lGQK56QzhRNpXzi8HQaPY/XeZgBduF1ERERERD4yddRA/vm66aza1ciP/2dr0uH0iPb45Tq8I3til12NjBhYytghZUlHJCIiIiIieeTaWWN4a+8RHnpjFzPGVHH1zNFJh3RWtMfvFHdo3IEPmcjqXY3MGz+0YE/VKiIiIiIi8bn7K1OYWzOYO5/ZwJb6o0mHc1ZibfzM7Etm9o6ZbTezu7pZ53oz22xmm8zsiZzxajN7xcy2RM/XxBkrbSdh2nUcHjaX9462MK+m8M7UIyIiIiIi8etXXMTSG2czsH8Jf7t83Scu+5CPYmv8zCwDLAW+DEwFFprZ1C7rTAb+Dvi8u08Dbs95+mfAT9x9CjAPOBhXrAD0K4drlvKbovkAzNWF20VEREREpBvnDezPA4tmc6DpJN97qpbOzk+5lkTC4tzjNw/Y7u473f1D4Eng6i7r/A2w1N0/AHD3gwBRg1js7iui8WZ3PxFjrB9ZvauRqrISzj9vQF/8OhERERERKVAXjRvC4q9O5bWtB1ny2rb/9+scOdnGmrrGXozsk+I8uctoYG/O433A/C7rnA9gZr8DMsA97v5yNN5kZs8C44FfAXe5e0eM8QKwpq6RuTWDKerm+h0iIiIiIiKnLLp4HG/ubeK+X21j+ugqrphy9tcCf3v/EZav3M3Paw9QWlLEqruvoLQ4E0ucSZ/VsxiYDFwGjAFeN7Pp0filwCxgD/AU8A3godwfNrObgZsBqqurzzmYhmOt7Dx0nBvmjj3n1xIRERERkfCZGf907XS21h/j9qdqefGWS6gZVtHt+i1tHfxiQz2PrdxN7d4m+pcUcc3M0Sy6eFxsTR/E2/jtB3I7qDHRWK59wCp3bwN2mdm7ZBvBfUCtu+8EMLPngYvp0vi5+zJgGcCcOXPO+aDatdHuVX2/T0REREREzlb/kgw//cuLuOr+N/jWY+t47rufo7zfx1ut3YeP8/iqPTy9di9NJ9qYMLyCxV+dytcuGkNVWTwXnc8VZ+O3BphsZuPJNnwLgBu7rPM8sBB4xMyGkT3EcyfQBAwys+Hu3gBcDqyNMVYAVu1qpKwkwwWjquL+VSIiIiIiEpCxQ8pZsmAWNz2ymjuf2ciSBTPpdHht60EeW7mb199tIFNkfHHaCBbNH8dnJ/bt5eNia/zcvd3MbgF+Sfb7ew+7+yYz+yGw1t1fiJ670sw2Ax3AD9z9MICZfR941bL/GuuAB+OK9ZQ1dY3Mqh5Ev2Jd3lBERERERHrmC+cP5/tXfoaf/PIdOjudN/d8wIEjLYwYWMrtfzaZBXOr+aOq/onEFut3/Nz9JeClLmOLc5YduCO6df3ZFcCMOOPLdayljS31R7n18sl99StFRERERCQw37lsIhv2NfGLjfV8ftJQFl81lSumjKAkk+zOpaRP7pI3KkuLeeV7f0JFaXxfqBQRERERkbCZGfffOJvDzR8mtnfvdNT4RcyMSedVJh2GiIiIiIgUuJJMUV41fRDvBdxFREREREQkD6jxExERERERCZwaPxERERERkcCp8RMREREREQmcGj8REREREZHAqfETEREREREJnBo/ERERERGRwKnxExERERERCZwaPxERERERkcCp8RMREREREQmcuXvSMfQKM2sAdp/mqWHAoR68VBVwpEDXT1OuoHyTjCdNufbF+sq358a5+/BzfI3U6KZG6n2XbDyFnG+acs3H9ZVvcrHkU67d6b4+unvQN2BtD9dfVqjrpylX5ZtsPGnKVfkmn69u8dz0vks8noLNN0255un6yrdwYs+r+qhDPT/pxQJfP87Xzrf1eyrf4i/kfNOUa1+s31P5Fn/c+Up+yLf3kf7Oelc+1YB8yjUf1++pfItf/7dNSDCHenbHzNa6+5yk4+gLacoVlG/I0pQrKF9JRtrmQfmGK025gvINWdy5pmGP37KkA+hDacoVlG/I0pQrKF9JRtrmQfmGK025gvINWay5Br/HT0REREREJO3SsMdPREREREQk1YJt/MzsS2b2jpltN7O7ko4nbmZWZ2YbzazWzNYmHU9vM7OHzeygmb2dMzbEzFaY2bbofnCSMfaWbnK9x8z2R/Nba2ZfSTLG3mRmY83s12a22cw2mdlt0Xhw83uGXIOcXzPrb2arzeytKN9/iMbHm9mqaPv8lJn1SzrWtFGNDEea6iOkq0amqT6CamRf1MggD/U0swzwLvDnwD5gDbDQ3TcnGliMzKwOmOPu53rtj7xkZl8AmoGfufsF0di9QKO7/zj6j8tgd78zyTh7Qze53gM0u/u/JBlbHMxsJDDS3deb2QBgHXAN8A0Cm98z5Ho9Ac6vmRlQ4e7NZlYCvAHcBtwBPOvuT5rZfwJvufsDScaaJqqRYUlTfYR01cg01UdQjaQPamSoe/zmAdvdfae7fwg8CVydcExyDtz9daCxy/DVwKPR8qNkNw4Fr5tcg+Xu9e6+Plo+BmwBRhPg/J4h1yB5VnP0sCS6OXA58N/ReBBzW2BUIwOSpvoI6aqRaaqPoBpJH9TIUBu/0cDenMf7CPiNE3HgFTNbZ2Y3Jx1MHxnh7vXR8nvAiCSD6QO3mNmG6DCXIA7r6MrMaoBZwCoCn98uuUKg82tmGTOrBQ4CK4AdQJO7t0erpGH7nG9UI8MX9PazG0FuQ09JU30E1ci4amSojV8aXeLus4EvA9+NDoVIDc8esxzecct/8AAwEZgJ1AP/mmw4vc/MKoFngNvd/Wjuc6HN72lyDXZ+3b3D3WcCY8juafrjhEOSdEptjQxt+9mNYLehkK76CKqRcf6+UBu//cDYnMdjorFgufv+6P4g8BzZN0/o3o+OBz91XPjBhOOJjbu/H20cOoEHCWx+o2PbnwEed/dno+Eg5/d0uYY+vwDu3gT8GvgsMMjMiqOngt8+5yHVyAD/xroIcvvZnZC3oWmqj6AaScw1MtTGbw0wOTorTj9gAfBCwjHFxswqoi/BYmYVwJXA22f+qSC8ANwULd8E/DzBWGJ1agMfuZaA5jf6cvNDwBZ3/7ecp4Kb3+5yDXV+zWy4mQ2KlsvInkxkC9ni9hfRakHMbYFRjQzkb+wMgtt+nknA29DU1EdQjaQPamSQZ/UEiE71eh+QAR529x8lHFJszGwC2U8wAYqBJ0LL18z+C7gMGAa8D/w98DzwNFAN7Aaud/eC/8J3N7leRvYQBwfqgG/lHN9f0MzsEuC3wEagMxq+m+xx/UHN7xlyXUiA82tmM8h+MT1D9oPGp939h9E260lgCPAmsMjdW5OLNH1UI8PJN031EdJVI9NUH0E1kj6okcE2fiIiIiIiIpIV6qGeIiIiIiIiElHjJyIiIiIiEjg1fiIiIiIiIoFT4yciIiIiIhI4NX4iIiIiIiKBU+MnkgfMrMPManNud/Xia9eYWRDXvBERkfRRjRTpHcWfvoqI9IGT7j4z6SBERETykGqkSC/QHj+RPGZmdWZ2r5ltNLPVZjYpGq8xs9fMbIOZvWpm1dH4CDN7zszeim6fi14qY2YPmtkmM3vFzMoSS0pERKQXqEaK9IwaP5H8UNblMJYbcp474u7TgfuB+6Kx/wAedfcZwOPAkmh8CfAbd78QmA1sisYnA0vdfRrQBHwt5nxERER6i2qkSC8wd086BpHUM7Nmd688zXgdcLm77zSzEuA9dx9qZoeAke7eFo3Xu/swM2sAxrh7a85r1AAr3H1y9PhOoMTd/zH+zERERM6NaqRI79AeP5H8590s90RrznIH+n6viIiEQTVS5Cyp8RPJfzfk3P9vtPx7YEG0/HXgt9Hyq8C3AcwsY2ZVfRWkiIhIAlQjRc6SPtEQyQ9lZlab8/hldz91uurBZraB7CeSC6OxW4FHzOwHQAPwV9H4bcAyM/trsp9afhuojz16ERGR+KhGivQCfcdPJI9F31+Y4+6Hko5FREQkn6hGivSMDvUUEREREREJnPb4iYiIiIiIBE57/ERERERERAKnxk9ERERERCRwavxEREREREQCp8ZPREREREQkcGr8REREREREAqfGT0REREREJHD/BxJSnwuZ7uy1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5lOzkexsxaV",
        "colab_type": "text"
      },
      "source": [
        "NOTE : One can see from the above plot that the training set accuracy of the model is higher than the validation set accuracy.\n",
        "\n",
        "Also one can notice that the training set loss of the model is lesser than the testing set loss of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKK3C55KLbUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf-0ks5NwCHx",
        "colab_type": "text"
      },
      "source": [
        "#### **HYPERPARAMETER** **TUNING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLoRBjypwKZj",
        "colab_type": "text"
      },
      "source": [
        "#### **What** **do** **you** **mean** **by** **hyperparameter** **tuning**?\n",
        "\n",
        "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K2SB4Cd5zyH",
        "colab_type": "text"
      },
      "source": [
        "**I** **will** **use** **grid** **search** **in** **scikit**-**learn** **library** **to** **tune** **the** **hyperparameters** **of** **my** **deep** **convolutional** **neural** **network** (**DCNN**).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F1L4SB07I7p",
        "colab_type": "text"
      },
      "source": [
        "The hyperparameters for my model are as follows :\n",
        "\n",
        "1. batch_size\n",
        "2. epochs\n",
        "3. lr (learning rate)\n",
        "4. optimizer\n",
        "5. activation\n",
        "6. Dropout (dropout regularization)\n",
        "7. kernel_initializer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYwCru0QXRfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the grid search function in scikit learn library\n",
        "# Importing GriDSearch from scikit-learn\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR3s-F8P8VZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the KerasClassifier class from the scikit-learn library\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5nz0LC19WFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the model architecture again with the same number of layers again in order to wrap the keras classifier in the scikit learn library\n",
        "def create_model():\n",
        "\n",
        "  input_shape = (64,64,3)\n",
        "  num_classes = 7\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
        "  model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same'))\n",
        "  model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='Same'))\n",
        "  model.add(MaxPool2D(pool_size= (2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "   \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJakZihRxYN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uEz73TYxPUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E-PibPJvD_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrK5faTo7oaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97be1a49-fce7-40ea-9f2e-91ff006115af"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7210, 64, 64, 3), (7210, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuxKpiG4xlR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the grid search parameters\n",
        "# batch_size = [10, 20, 40, 60, 80, 100]\n",
        "# epochs = [10, 50, 100]\n",
        "param_grid = {'batch_size': [10, 20, 30], 'epochs' : [10,25,40]}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7nBhFKVHwyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "41b5d453-2293-4f97-f816-d882a602d329"
      },
      "source": [
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params'] \n",
        "for mean, stdev, param in zip(means, stds, params):   \n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.752565 using {'batch_size': 30, 'epochs': 10}\n",
            "0.739528 (0.005049) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.726907 (0.005519) with: {'batch_size': 10, 'epochs': 25}\n",
            "0.729542 (0.006355) with: {'batch_size': 10, 'epochs': 40}\n",
            "0.740082 (0.011134) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.730098 (0.002714) with: {'batch_size': 20, 'epochs': 25}\n",
            "0.727181 (0.019169) with: {'batch_size': 20, 'epochs': 40}\n",
            "0.752565 (0.004244) with: {'batch_size': 30, 'epochs': 10}\n",
            "0.749097 (0.008950) with: {'batch_size': 30, 'epochs': 25}\n",
            "0.735643 (0.012216) with: {'batch_size': 30, 'epochs': 40}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nrJfI0-qGlf",
        "colab_type": "text"
      },
      "source": [
        "**NOTE** : From the above hyperparameter tuning algorithm, one can see that the batch_size was given the values as 10, 20. 30, while the epoch values were given as 10, 25, 40 from which the best efficiency of the model was achieved at a batch size of 30 and epoch value as 10 and which was 75.25% accuracy.\n",
        "\n",
        "But one can also notice that the model which was trained with an epoch value of 30 and batch size of 64 gave higher accuracy of 77.85% as compared to the model which was found as the best performing model from hyperparameter tuning. Hence considering the previous model as our final model for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGSjJ6tjA-Fk",
        "colab_type": "text"
      },
      "source": [
        "**PLOTTING** **THE** **CONFUSION** **MATRIX** **IN** **ORDER** **TO** **CHECK** **HOW** **ACCURATE** **ARE** **OUR** **PREDICTIONS** ARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PjM1l6cyhke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "a32d9691-f527-4183-92eb-03fb20852088"
      },
      "source": [
        "# Function to plot confusion matrix    \n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(X_val)\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(y_val,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(7)) \n",
        "   "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHZ9BCA3ynLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ea7be0a0-215a-41c7-f707-b1b5ed1c152f"
      },
      "source": [
        "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
        "plt.bar(np.arange(7),label_frac_error)\n",
        "plt.xlabel('True Label')\n",
        "plt.ylabel('Fraction classified incorrectly')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Fraction classified incorrectly')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alUM7gifysQD",
        "colab_type": "text"
      },
      "source": [
        "**CONCLUSION** : It seems our model has maximum number of incorrect predictions for Basal cell carcinoma which has code 3, then second most missclassified type is Vascular lesions code 5 then Melanocytic nevi code 0 where as Actinic keratoses code 4 has least misclassified type.\n",
        "\n",
        "We can also further tune our model to easily achieve the accuracy above 80% and I think still this model is efficient in comparison to detection with human eyes having 77.0344% accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIRu32mPRb3f",
        "colab_type": "text"
      },
      "source": [
        "**CONTRIBUTION** : \n",
        "\n",
        "Code by self----70%\n",
        "\n",
        "Code by reference----30%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEqYRc1FRn3H",
        "colab_type": "text"
      },
      "source": [
        "**CITATIONS** :\n",
        "\n",
        "SKIN CANCER MNIST DATASET KAGGLE: https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000\n",
        "\n",
        "OVERVIEW OF IMAGE CLASSIFICATION USING CNN: https://analyticsindiamag.com/deep-learning-image-classification-with-cnn-an-overview/\n",
        "\n",
        "GRIDSEARCHCV DOCUMENTATION : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWNmDMUiR-bc",
        "colab_type": "text"
      },
      "source": [
        " **LICENSE** : \n",
        "\n",
        "Copyright 2019 Ria Rajput\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RLBEV7Ry4Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}